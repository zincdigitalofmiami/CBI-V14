# Dual-Asset Organization Design (ZL + MES)
**Date:** November 18, 2025  
**Status:** RESEARCH - NO EXECUTION  
**Questions:** How to organize for 2 primary targets, shared vs. separate data, intraday training, meta-learning

---

## ğŸ¯ QUESTION 1: How to Organize for Two Primary Targets?

### Industry Pattern: SHARED + ASSET-SPECIFIC Architecture

```
/TrainingData/
â”‚
â”œâ”€â”€ ğŸ“ shared/                           â† Data used by BOTH ZL and MES
â”‚   â”œâ”€â”€ macro/
â”‚   â”‚   â”œâ”€â”€ fred_economic.parquet        â† Used by both
â”‚   â”‚   â”œâ”€â”€ vix_volatility.parquet       â† Used by both
â”‚   â”‚   â””â”€â”€ fx_rates.parquet             â† Used by both
â”‚   â”‚
â”‚   â”œâ”€â”€ market_regime/
â”‚   â”‚   â”œâ”€â”€ regime_calendar.parquet      â† Shared regime classification
â”‚   â”‚   â”œâ”€â”€ volatility_regime.parquet
â”‚   â”‚   â””â”€â”€ policy_regime.parquet
â”‚   â”‚
â”‚   â”œâ”€â”€ intelligence/
â”‚   â”‚   â”œâ”€â”€ news_sentiment.parquet       â† Macro news affects both
â”‚   â”‚   â”œâ”€â”€ policy_events.parquet        â† Trade/macro policy affects both
â”‚   â”‚   â””â”€â”€ hidden_relationships.parquet
â”‚   â”‚
â”‚   â””â”€â”€ cross_asset/
â”‚       â”œâ”€â”€ correlations.parquet         â† ZL-MES correlation tracking
â”‚       â””â”€â”€ regime_transitions.parquet
â”‚
â”œâ”€â”€ ğŸ“ ZL/                               â† ZL-SPECIFIC (Soybean Oil)
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ databento_ZL/               â† ZL futures only
â”‚   â”‚   â”œâ”€â”€ yahoo_ZL_F/                 â† ZL historical only
â”‚   â”‚   â””â”€â”€ continuous_contracts/
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ zl_specific/
â”‚   â”‚   â”‚   â”œâ”€â”€ crush_oilshare/         â† Only relevant for ZL
â”‚   â”‚   â”‚   â”œâ”€â”€ soybean_complex/        â† ZS, ZM relationships
â”‚   â”‚   â”‚   â”œâ”€â”€ palm_substitution/      â† Palm oil competition
â”‚   â”‚   â”‚   â”œâ”€â”€ biofuel_demand/         â† Biodiesel, RINs
â”‚   â”‚   â”‚   â”œâ”€â”€ usda_soy/               â† Soybean-specific USDA
â”‚   â”‚   â”‚   â”œâ”€â”€ weather_soy_belt/       â† US/Brazil/Argentina soy weather
â”‚   â”‚   â”‚   â””â”€â”€ china_soy_demand/       â† China soy imports
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ master_features/
â”‚   â”‚       â””â”€â”€ ZL_master_2000_2025.parquet  â† Shared + ZL-specific
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ by_horizon/
â”‚   â”‚       â”œâ”€â”€ 1w/ ... 1m/ ... 3m/ ... 6m/ ... 12m/
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ by_horizon/
â”‚   â”‚
â”‚   â””â”€â”€ predictions/
â”‚       â””â”€â”€ by_horizon/
â”‚
â””â”€â”€ ğŸ“ MES/                              â† MES-SPECIFIC (Micro E-mini S&P 500)
    â”œâ”€â”€ raw/
    â”‚   â”œâ”€â”€ databento_MES/              â† MES futures only
    â”‚   â”‚   â”œâ”€â”€ tick/                   â† Tick-by-tick
    â”‚   â”‚   â”œâ”€â”€ 1min/                   â† 1-minute bars
    â”‚   â”‚   â”œâ”€â”€ trades/                 â† Trade data
    â”‚   â”‚   â”œâ”€â”€ quotes_tbbo/            â† Top of book
    â”‚   â”‚   â””â”€â”€ depth_mbp10/            â† Market by price (10 levels)
    â”‚   â”‚
    â”‚   â””â”€â”€ es_reference/               â† ES for comparison
    â”‚
    â”œâ”€â”€ features/
    â”‚   â”œâ”€â”€ mes_specific/
    â”‚   â”‚   â”œâ”€â”€ microstructure/         â† Only relevant for MES
    â”‚   â”‚   â”‚   â”œâ”€â”€ order_imbalance/
    â”‚   â”‚   â”‚   â”œâ”€â”€ microprice_deviation/
    â”‚   â”‚   â”‚   â”œâ”€â”€ trade_aggressor/
    â”‚   â”‚   â”‚   â”œâ”€â”€ quote_intensity/
    â”‚   â”‚   â”‚   â””â”€â”€ depth_metrics/
    â”‚   â”‚   â”œâ”€â”€ intraday_patterns/
    â”‚   â”‚   â”‚   â”œâ”€â”€ opening_auction/
    â”‚   â”‚   â”‚   â”œâ”€â”€ lunch_hour/
    â”‚   â”‚   â”‚   â””â”€â”€ close_patterns/
    â”‚   â”‚   â”œâ”€â”€ equity_specific/
    â”‚   â”‚   â”‚   â”œâ”€â”€ earnings_proximity/
    â”‚   â”‚   â”‚   â”œâ”€â”€ index_rebalancing/
    â”‚   â”‚   â”‚   â””â”€â”€ dividend_effects/
    â”‚   â”‚   â””â”€â”€ risk_metrics/
    â”‚   â”‚       â”œâ”€â”€ vix_relationship/
    â”‚   â”‚       â””â”€â”€ sector_rotation/
    â”‚   â”‚
    â”‚   â””â”€â”€ master_features/
    â”‚       â”œâ”€â”€ by_timeframe/
    â”‚       â”‚   â”œâ”€â”€ MES_1min_features.parquet    â† Micro features
    â”‚       â”‚   â”œâ”€â”€ MES_5min_features.parquet
    â”‚       â”‚   â”œâ”€â”€ MES_15min_features.parquet
    â”‚       â”‚   â”œâ”€â”€ MES_30min_features.parquet
    â”‚       â”‚   â”œâ”€â”€ MES_1hr_features.parquet
    â”‚       â”‚   â”œâ”€â”€ MES_4hr_features.parquet
    â”‚       â”‚   â””â”€â”€ MES_daily_features.parquet   â† Aggregated features
    â”‚       â””â”€â”€ MES_master_intraday_2010_2025.parquet
    â”‚
    â”œâ”€â”€ training/
    â”‚   â””â”€â”€ by_horizon/
    â”‚       â”œâ”€â”€ intraday_micro/          â† 1min, 5min, 15min, 30min
    â”‚       â”œâ”€â”€ intraday_macro/          â† 1hr, 4hr
    â”‚       â”œâ”€â”€ daily/                   â† 1d, 7d, 30d
    â”‚       â””â”€â”€ monthly/                 â† 3m, 6m, 12m
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ neural_intraday/             â† LSTM, TCN for micro timeframes
    â”‚   â”œâ”€â”€ tree_daily/                  â† LightGBM for daily+
    â”‚   â””â”€â”€ meta_learner/                â† Meta-learning models
    â”‚
    â””â”€â”€ predictions/
        â””â”€â”€ by_horizon/
            â””â”€â”€ ... (12 horizons)
```

---

## ğŸ¯ QUESTION 2: How to Share Datasets but Keep Separate?

### Solution: LAYERED COMPOSITION Pattern

**Layer 1: Shared Foundation** (Used by both ZL and MES)
```
shared/
â”œâ”€â”€ macro/
â”‚   â”œâ”€â”€ fred_rates.parquet              â† Affects both
â”‚   â”œâ”€â”€ fed_policy.parquet              â† Affects both
â”‚   â””â”€â”€ dollar_index.parquet            â† Affects both
â”‚
â”œâ”€â”€ volatility/
â”‚   â”œâ”€â”€ vix_daily.parquet               â† Risk-off affects both
â”‚   â””â”€â”€ volatility_regime.parquet       â† Shared regime
â”‚
â”œâ”€â”€ intelligence/
â”‚   â”œâ”€â”€ macro_news.parquet              â† Fed, trade policy
â”‚   â””â”€â”€ geopolitical_events.parquet     â† War, elections
â”‚
â””â”€â”€ regimes/
    â””â”€â”€ global_regime_calendar.parquet  â† Crisis, bull, bear, normal
```

**Layer 2: ZL-Specific** (ZL only, never MES)
```
ZL/
â”œâ”€â”€ zl_specific_raw/
â”‚   â”œâ”€â”€ crush_margins.parquet           â† ZL only
â”‚   â”œâ”€â”€ palm_oil_prices.parquet         â† ZL substitution
â”‚   â”œâ”€â”€ biodiesel_production.parquet    â† ZL demand
â”‚   â”œâ”€â”€ soybean_complex.parquet         â† ZS, ZM
â”‚   â”œâ”€â”€ china_soy_imports.parquet       â† ZL specific
â”‚   â””â”€â”€ brazil_argentina_weather.parquet â† ZL crop weather
â”‚
â””â”€â”€ zl_specific_regimes/
    â””â”€â”€ biofuel_policy_regime.parquet   â† ZL-specific regime
```

**Layer 3: MES-Specific** (MES only, never ZL)
```
MES/
â”œâ”€â”€ mes_specific_raw/
â”‚   â”œâ”€â”€ es_futures.parquet              â† ES reference
â”‚   â”œâ”€â”€ spx_index.parquet               â† Underlying index
â”‚   â”œâ”€â”€ sector_etfs.parquet             â† XLF, XLE, etc.
â”‚   â”œâ”€â”€ earnings_calendar.parquet       â† Equity-specific
â”‚   â””â”€â”€ microstructure/
â”‚       â”œâ”€â”€ order_book_1min.parquet     â† Depth data
â”‚       â”œâ”€â”€ trades_tick.parquet         â† Trade-by-trade
â”‚       â””â”€â”€ quotes_tbbo.parquet         â† Top of book
â”‚
â””â”€â”€ mes_specific_regimes/
    â””â”€â”€ equity_market_regime.parquet    â† Bull/bear for equities
```

**Composition in Code:**
```python
# For ZL training
zl_features = (
    load_shared_macro()           # Shared layer
    + load_shared_volatility()    # Shared layer  
    + load_zl_specific_crush()    # ZL-only layer
    + load_zl_specific_weather()  # ZL-only layer
)

# For MES training
mes_features = (
    load_shared_macro()           # Shared layer (SAME DATA)
    + load_shared_volatility()    # Shared layer (SAME DATA)
    + load_mes_specific_micro()   # MES-only layer
    + load_mes_specific_equity()  # MES-only layer
)
```

**Benefit:** 
- Shared data stored once (FRED, VIX, etc.)
- Asset-specific data isolated
- Easy to maintain
- Clear what's shared vs. unique

---

## ğŸ¯ QUESTION 3: Micro-Training on Hyper Sets for Lower Timeframes

### Pattern: TIMEFRAME-SPECIFIC FEATURE SETS

**Problem:** MES 1-minute model needs DIFFERENT features than MES 1-month model

**Solution:** Organize by timeframe granularity

```
MES/features/by_timeframe/
â”‚
â”œâ”€â”€ ğŸ“ micro_1min/                       â† INTRADAY MICRO (1min)
â”‚   â”œâ”€â”€ microstructure/
â”‚   â”‚   â”œâ”€â”€ order_imbalance_1min.parquet
â”‚   â”‚   â”œâ”€â”€ microprice_deviation_1min.parquet
â”‚   â”‚   â”œâ”€â”€ spread_1min.parquet
â”‚   â”‚   â”œâ”€â”€ depth_imbalance_1min.parquet
â”‚   â”‚   â””â”€â”€ trade_flow_1min.parquet
â”‚   â”‚
â”‚   â”œâ”€â”€ technical_micro/
â”‚   â”‚   â”œâ”€â”€ rsi_1min.parquet
â”‚   â”‚   â”œâ”€â”€ vwap_deviation_1min.parquet
â”‚   â”‚   â””â”€â”€ volume_intensity_1min.parquet
â”‚   â”‚
â”‚   â””â”€â”€ master_features_1min.parquet     â† 150-200 micro features
â”‚       Features: order_imbalance, microprice, spread, depth, flow,
â”‚                 vwap, volume_intensity, NO macro, NO fundamentals
â”‚
â”œâ”€â”€ ğŸ“ micro_5min/                       â† INTRADAY MICRO (5min)
â”‚   â””â”€â”€ master_features_5min.parquet     â† Aggregated from 1min
â”‚
â”œâ”€â”€ ğŸ“ micro_15min/                      â† INTRADAY MICRO (15min)
â”‚   â””â”€â”€ master_features_15min.parquet
â”‚
â”œâ”€â”€ ğŸ“ micro_30min/                      â† INTRADAY MICRO (30min)
â”‚   â””â”€â”€ master_features_30min.parquet
â”‚
â”œâ”€â”€ ğŸ“ macro_1hr/                        â† INTRADAY MACRO (1hr)
â”‚   â”œâ”€â”€ microstructure/                  â† Still has micro features
â”‚   â”œâ”€â”€ macro_snapshots/                 â† START adding macro
â”‚   â”‚   â”œâ”€â”€ vix_hourly.parquet
â”‚   â”‚   â””â”€â”€ fx_hourly.parquet
â”‚   â””â”€â”€ master_features_1hr.parquet      â† 180-220 features (micro + some macro)
â”‚
â”œâ”€â”€ ğŸ“ macro_4hr/                        â† INTRADAY MACRO (4hr)
â”‚   â””â”€â”€ master_features_4hr.parquet      â† 200-250 features (more macro)
â”‚
â”œâ”€â”€ ğŸ“ daily/                            â† MULTI-DAY (1d, 7d, 30d)
â”‚   â”œâ”€â”€ microstructure_aggregated/       â† Daily aggregates of micro
â”‚   â”œâ”€â”€ fundamentals/                    â† NOW add fundamentals
â”‚   â”‚   â”œâ”€â”€ earnings.parquet
â”‚   â”‚   â””â”€â”€ economic_releases.parquet
â”‚   â””â”€â”€ master_features_daily.parquet    â† 250-300 features (micro agg + macro + fundamentals)
â”‚
â””â”€â”€ ğŸ“ monthly/                          â† MULTI-MONTH (3m, 6m, 12m)
    â””â”€â”€ master_features_monthly.parquet  â† 200-250 features (mostly macro + fundamentals, less micro)
```

**Feature Count by Timeframe:**
- **1min-30min (micro):** 150-200 features (90% microstructure, 10% technical)
- **1hr-4hr (transitional):** 180-250 features (60% microstructure, 30% macro, 10% technical)
- **1d-30d (daily):** 250-300 features (30% micro aggregates, 50% macro, 20% fundamentals)
- **3m-12m (monthly):** 200-250 features (10% micro, 40% macro, 50% fundamentals)

**Training Strategy:**
```python
# 1-minute model
train_1min_model(
    features=load_micro_features_1min(),  # 150-200 micro features
    architecture="LSTM",                  # Neural net for intraday
    batch_size=32,                        # Small batches
    sequence_length=60                    # Last 60 minutes
)

# 1-month model
train_1m_model(
    features=load_monthly_features(),     # 200-250 macro/fundamental
    architecture="LightGBM",              # Tree model for long horizon
    n_estimators=1000
)
```

---

## ğŸ¯ QUESTION 4: Meta-Learning (Learn to Learn)

### Pattern: MAML-Style Meta-Learning for Time Series

**Concept:** Train a model that can QUICKLY ADAPT to new regimes with minimal data

**Organization for Meta-Learning:**
```
/TrainingData/meta_learning/
â”‚
â”œâ”€â”€ ğŸ“ meta_training_tasks/              â† Each regime = one "task"
â”‚   â”œâ”€â”€ task_001_trump_2023_2025/
â”‚   â”‚   â”œâ”€â”€ support_set.parquet          â† Small sample for adaptation
â”‚   â”‚   â””â”€â”€ query_set.parquet            â† Test adaptation
â”‚   â”‚
â”‚   â”œâ”€â”€ task_002_trade_war_2017_2019/
â”‚   â”‚   â”œâ”€â”€ support_set.parquet
â”‚   â”‚   â””â”€â”€ query_set.parquet
â”‚   â”‚
â”‚   â”œâ”€â”€ task_003_crisis_2008/
â”‚   â”‚   â”œâ”€â”€ support_set.parquet
â”‚   â”‚   â””â”€â”€ query_set.parquet
â”‚   â”‚
â”‚   â””â”€â”€ ... (11 tasks = 11 regimes)
â”‚
â”œâ”€â”€ ğŸ“ meta_model/
â”‚   â”œâ”€â”€ base_model.keras                 â† Meta-learned initialization
â”‚   â”œâ”€â”€ adaptation_parameters/
â”‚   â”‚   â”œâ”€â”€ learning_rate.yaml
â”‚   â”‚   â””â”€â”€ adaptation_steps.yaml
â”‚   â””â”€â”€ performance/
â”‚       â””â”€â”€ few_shot_performance.csv     â† How well it adapts
â”‚
â””â”€â”€ ğŸ“ regime_adaptation/
    â”œâ”€â”€ new_regime_detected/
    â”‚   â”œâ”€â”€ regime_signature.parquet     â† New regime characteristics
    â”‚   â”œâ”€â”€ adaptation_data.parquet      â† Last 30 days
    â”‚   â””â”€â”€ adapted_model.keras          â† Fine-tuned from meta-model
    â”‚
    â””â”€â”€ adaptation_history/
        â””â”€â”€ all_adaptations.csv
```

**Meta-Learning Process:**
```python
# Step 1: Meta-Training (Train on 11 regimes)
for regime in all_regimes:
    support_data = load_regime_support_set(regime)   # Small sample
    query_data = load_regime_query_set(regime)       # Test sample
    
    # Inner loop: Adapt to regime
    adapted_model = meta_model.clone()
    adapted_model.fit(support_data, epochs=5)
    
    # Outer loop: Update meta-model to adapt faster
    loss = adapted_model.evaluate(query_data)
    meta_model.update_from_loss(loss)

# Step 2: When New Regime Detected
new_regime_data = load_last_30_days()  # Only 30 days!
adapted_model = meta_model.clone()
adapted_model.fit(new_regime_data, epochs=5)  # Quick adaptation
# Now adapted_model is tuned for new regime
```

**Key Files:**
1. `meta_training_tasks/` - One folder per regime (11 total)
2. `meta_model/base_model.keras` - The "learn to learn" model
3. `regime_adaptation/` - Quick fine-tuning when regime shifts

**Benefit:**
- NEW regime detected? Adapt in 5 epochs (not 100)
- Uses 30 days of data (not 5 years)
- Fast to production (hours, not weeks)

---

## ğŸ¯ COMPLETE DUAL-ASSET ARCHITECTURE

```
/Volumes/Satechi Hub/Projects/CBI-V14/TrainingData/
â”‚
â”œâ”€â”€ ğŸ“ SHARED/                           â† LAYER 0: Both assets use this
â”‚   â”œâ”€â”€ macro/
â”‚   â”‚   â”œâ”€â”€ fred/
â”‚   â”‚   â”œâ”€â”€ vix/
â”‚   â”‚   â””â”€â”€ fx/
â”‚   â”œâ”€â”€ regimes/
â”‚   â”‚   â”œâ”€â”€ global_regime_calendar.parquet
â”‚   â”‚   â”œâ”€â”€ volatility_regime.parquet
â”‚   â”‚   â””â”€â”€ policy_regime.parquet
â”‚   â””â”€â”€ intelligence/
â”‚       â”œâ”€â”€ macro_news/
â”‚       â””â”€â”€ policy_events/
â”‚
â”œâ”€â”€ ğŸ“ ZL/                               â† LAYER 1: Soybean Oil (Primary)
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ databento_ZL/
â”‚   â”‚   â”œâ”€â”€ yahoo_ZL_F/
â”‚   â”‚   â”œâ”€â”€ crush_margins/
â”‚   â”‚   â”œâ”€â”€ palm_oil/
â”‚   â”‚   â”œâ”€â”€ biodiesel/
â”‚   â”‚   â”œâ”€â”€ usda_soy/
â”‚   â”‚   â”œâ”€â”€ china_soy/
â”‚   â”‚   â””â”€â”€ weather_soy/
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ zl_specific/               â† Crush, palm, biodiesel, weather
â”‚   â”‚   â””â”€â”€ master_features/
â”‚   â”‚       â””â”€â”€ ZL_master_2000_2025.parquet  â† Shared + ZL features
â”‚   â”‚
â”‚   â”œâ”€â”€ regimes/
â”‚   â”‚   â””â”€â”€ biofuel_policy_regime.parquet    â† ZL-specific regime
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ by_horizon/                â† 5 horizons (1w, 1m, 3m, 6m, 12m)
â”‚   â”‚   â”‚   â”œâ”€â”€ 1w/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ all_regimes.parquet
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ by_regime/
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ regime=trump_2023_2025/
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ... (11 regimes)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ walk_forward_folds/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ fold_001/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ... (60 folds)
â”‚   â”‚   â”‚   â””â”€â”€ ... (1m, 3m, 6m, 12m)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ by_regime/                 â† 11 regimes
â”‚   â”‚       â””â”€â”€ ... (each regime Ã— 5 horizons)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baselines/                 â† ARIMA, Prophet, LightGBM, XGBoost
â”‚   â”‚   â”œâ”€â”€ advanced/                  â† TCN, LSTM, attention
â”‚   â”‚   â”œâ”€â”€ regime_specific/           â† Per-regime models
â”‚   â”‚   â””â”€â”€ meta_learner/              â† Meta-learning model
â”‚   â”‚
â”‚   â”œâ”€â”€ predictions/
â”‚   â”‚   â”œâ”€â”€ point/
â”‚   â”‚   â””â”€â”€ quantiles/
â”‚   â”‚
â”‚   â””â”€â”€ performance/
â”‚       â”œâ”€â”€ sharpe_tracking/
â”‚       â”œâ”€â”€ shap_values/
â”‚       â””â”€â”€ monte_carlo/
â”‚
â””â”€â”€ ğŸ“ MES/                              â† LAYER 2: Micro E-mini (Secondary/Hidden)
    â”œâ”€â”€ raw/
    â”‚   â”œâ”€â”€ databento_MES/
    â”‚   â”‚   â”œâ”€â”€ tick/
    â”‚   â”‚   â”œâ”€â”€ 1min/
    â”‚   â”‚   â”œâ”€â”€ trades/
    â”‚   â”‚   â”œâ”€â”€ quotes/
    â”‚   â”‚   â””â”€â”€ depth/
    â”‚   â”‚
    â”‚   â”œâ”€â”€ equity_specific/
    â”‚   â”‚   â”œâ”€â”€ earnings/
    â”‚   â”‚   â”œâ”€â”€ sector_rotation/
    â”‚   â”‚   â””â”€â”€ index_rebalancing/
    â”‚   â”‚
    â”‚   â””â”€â”€ microstructure_raw/
    â”‚       â”œâ”€â”€ order_flow/
    â”‚       â””â”€â”€ liquidity/
    â”‚
    â”œâ”€â”€ features/
    â”‚   â”œâ”€â”€ by_timeframe/              â† CRITICAL: Different features per timeframe
    â”‚   â”‚   â”œâ”€â”€ 1min/
    â”‚   â”‚   â”‚   â””â”€â”€ micro_features_150.parquet    â† 150 micro features
    â”‚   â”‚   â”œâ”€â”€ 5min/
    â”‚   â”‚   â”œâ”€â”€ 15min/
    â”‚   â”‚   â”œâ”€â”€ 30min/
    â”‚   â”‚   â”œâ”€â”€ 1hr/
    â”‚   â”‚   â”œâ”€â”€ 4hr/
    â”‚   â”‚   â”œâ”€â”€ 1d/
    â”‚   â”‚   â”‚   â””â”€â”€ daily_features_250.parquet    â† 250 features (micro agg + macro)
    â”‚   â”‚   â””â”€â”€ ... (12 timeframes)
    â”‚   â”‚
    â”‚   â””â”€â”€ master_features/
    â”‚       â””â”€â”€ MES_master_by_timeframe.parquet
    â”‚
    â”œâ”€â”€ training/
    â”‚   â””â”€â”€ by_horizon/                â† 12 horizons organized by timeframe type
    â”‚       â”œâ”€â”€ intraday_micro/        â† Neural nets (LSTM, TCN)
    â”‚       â”‚   â”œâ”€â”€ 1min/
    â”‚       â”‚   â”œâ”€â”€ 5min/
    â”‚       â”‚   â”œâ”€â”€ 15min/
    â”‚       â”‚   â””â”€â”€ 30min/
    â”‚       â”‚
    â”‚       â”œâ”€â”€ intraday_macro/        â† Neural nets
    â”‚       â”‚   â”œâ”€â”€ 1hr/
    â”‚       â”‚   â””â”€â”€ 4hr/
    â”‚       â”‚
    â”‚       â”œâ”€â”€ multiday/              â† Tree models (LightGBM)
    â”‚       â”‚   â”œâ”€â”€ 1d/
    â”‚       â”‚   â”œâ”€â”€ 7d/
    â”‚       â”‚   â””â”€â”€ 30d/
    â”‚       â”‚
    â”‚       â””â”€â”€ multimonth/            â† Tree models
    â”‚           â”œâ”€â”€ 3m/
    â”‚           â”œâ”€â”€ 6m/
    â”‚           â””â”€â”€ 12m/
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ neural_intraday/           â† For 1min-4hr
    â”‚   â”‚   â”œâ”€â”€ lstm_1min/
    â”‚   â”‚   â”œâ”€â”€ tcn_5min/
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”‚
    â”‚   â”œâ”€â”€ tree_daily/                â† For 1d-12m
    â”‚   â”‚   â”œâ”€â”€ lightgbm_1d/
    â”‚   â”‚   â””â”€â”€ xgboost_30d/
    â”‚   â”‚
    â”‚   â””â”€â”€ meta_learner/              â† Transfer learning across timeframes
    â”‚       â”œâ”€â”€ base_model.keras
    â”‚       â””â”€â”€ adapted_models/
    â”‚           â”œâ”€â”€ adapted_1min.keras
    â”‚           â””â”€â”€ ...
    â”‚
    â””â”€â”€ performance/
        â”œâ”€â”€ by_timeframe/
        â”‚   â”œâ”€â”€ intraday_metrics/      â† MAPE for 1min-4hr
        â”‚   â””â”€â”€ daily_metrics/         â† MAPE for 1d-12m
        â””â”€â”€ meta_learning_performance/
```

**Training Data Volume by Timeframe:**

**Micro (1min-30min):**
- Data points: 390 bars/day Ã— 252 days/year Ã— 15 years = ~1.5M rows per timeframe
- Features: 150-200 (microstructure-heavy)
- Model type: Neural (LSTM, TCN)
- Batch size: 32
- Sequence length: 60 bars (1 hour of 1min bars)

**Macro (1hr-4hr):**
- Data points: ~98 bars/day Ã— 252 Ã— 15 = ~370K rows per timeframe
- Features: 180-250 (micro + macro blend)
- Model type: Neural (LSTM, TCN)
- Batch size: 32
- Sequence length: 24 bars (1 day of 1hr bars)

**Daily+ (1d-12m):**
- Data points: 252 days/year Ã— 15 years = ~3.8K rows
- Features: 200-300 (macro + fundamentals heavy)
- Model type: Tree (LightGBM, XGBoost)
- No sequence needed (tabular)

---

## ğŸ¯ META-LEARNING ORGANIZATION (Learn to Learn)

### Implementation Pattern:

```
/meta_learning/
â”‚
â”œâ”€â”€ ğŸ“ meta_training_setup/
â”‚   â”œâ”€â”€ task_definition/
â”‚   â”‚   â”œâ”€â”€ regime_tasks/              â† Each regime = one task
â”‚   â”‚   â”‚   â”œâ”€â”€ trump_2023_2025/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ support_set_30days.parquet    â† Small sample
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ query_set_30days.parquet      â† Test sample
â”‚   â”‚   â”‚   â”œâ”€â”€ crisis_2008/
â”‚   â”‚   â”‚   â””â”€â”€ ... (11 regime tasks)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ timeframe_tasks/           â† Each timeframe = one task
â”‚   â”‚       â”œâ”€â”€ 1min_to_5min_transfer/
â”‚   â”‚       â”œâ”€â”€ 5min_to_15min_transfer/
â”‚   â”‚       â””â”€â”€ ... (transfer between timeframes)
â”‚   â”‚
â”‚   â”œâ”€â”€ base_models/
â”‚   â”‚   â”œâ”€â”€ zl_base_metalearner.keras  â† Meta-learned for ZL
â”‚   â”‚   â””â”€â”€ mes_base_metalearner.keras â† Meta-learned for MES
â”‚   â”‚
â”‚   â””â”€â”€ adaptation_protocols/
â”‚       â”œâ”€â”€ few_shot_5epoch.yaml
â”‚       â””â”€â”€ regime_shift_10epoch.yaml
â”‚
â”œâ”€â”€ ğŸ“ transfer_learning/
â”‚   â”œâ”€â”€ cross_timeframe/
â”‚   â”‚   â”œâ”€â”€ 1min_pretrained.keras      â† Pre-trained on 1min
â”‚   â”‚   â”œâ”€â”€ fine_tuned_for_5min.keras  â† Fine-tuned for 5min
â”‚   â”‚   â””â”€â”€ fine_tuned_for_15min.keras
â”‚   â”‚
â”‚   â””â”€â”€ cross_regime/
â”‚       â”œâ”€â”€ general_pretrained.keras    â† Trained on all regimes
â”‚       â”œâ”€â”€ adapted_crisis.keras        â† Fine-tuned for crisis
â”‚       â””â”€â”€ adapted_trump.keras         â† Fine-tuned for Trump era
â”‚
â””â”€â”€ ğŸ“ few_shot_learning/
    â”œâ”€â”€ new_regime_samples/
    â”‚   â””â”€â”€ last_30_days.parquet        â† When new regime detected
    â”‚
    â””â”€â”€ adapted_models/
        â””â”€â”€ quick_adaptation_20251118.keras  â† Adapted in 5 epochs
```

**Meta-Learning Process:**
```python
# STEP 1: Meta-Training (One-time, expensive)
meta_model = build_base_architecture()

for regime_task in all_11_regimes:
    # Inner loop: Adapt quickly to regime
    support_set = load_regime_support(regime_task)  # 30 days only
    query_set = load_regime_query(regime_task)      # Test set
    
    # Clone and adapt
    adapted = meta_model.clone()
    adapted.fit(support_set, epochs=5)  # Just 5 epochs!
    
    # Measure adaptation quality
    loss = adapted.evaluate(query_set)
    
    # Outer loop: Update meta-model to adapt faster
    meta_model.meta_update(loss)

# Save meta-learned model
meta_model.save('zl_base_metalearner.keras')

# STEP 2: Fast Adaptation (When needed)
# New regime detected! (e.g., "Trump 2.0 Tariff War")
new_regime_data = load_last_30_days()  # Only 30 days!

# Clone meta-model
quick_model = load_meta_model('zl_base_metalearner.keras')

# Adapt in just 5 epochs (NOT 100 epochs!)
quick_model.fit(new_regime_data, epochs=5)

# Ready for production in MINUTES, not WEEKS
```

**Benefit:**
- Model "learns how to adapt" during meta-training
- When new regime appears, adapts with tiny data (30 days vs. 5 years)
- Fast to production (hours vs. weeks)
- Performs well even with limited new regime data

---

## ğŸ¯ CROSS-ASSET KNOWLEDGE SHARING

### Pattern: Transfer Learning Between ZL and MES

```
/transfer_learning/
â”‚
â”œâ”€â”€ ğŸ“ shared_representations/
â”‚   â”œâ”€â”€ macro_encoder.keras            â† Learns macro patterns (used by both)
â”‚   â”œâ”€â”€ volatility_encoder.keras       â† Learns vol patterns (used by both)
â”‚   â””â”€â”€ regime_encoder.keras           â† Learns regime patterns (used by both)
â”‚
â”œâ”€â”€ ğŸ“ ZL_specific/
â”‚   â”œâ”€â”€ zl_head.keras                  â† ZL-specific prediction head
â”‚   â””â”€â”€ zl_fine_tuned.keras            â† Full ZL model (shared encoder + ZL head)
â”‚
â””â”€â”€ ğŸ“ MES_specific/
    â”œâ”€â”€ mes_head.keras                 â† MES-specific prediction head
    â””â”€â”€ mes_fine_tuned.keras           â† Full MES model (shared encoder + MES head)
```

**Training Process:**
```python
# Step 1: Pre-train shared encoder on ALL data (ZL + MES)
shared_encoder = train_on_macro_features(
    data=load_shared_macro() + load_zl_data() + load_mes_data()
)

# Step 2: Fine-tune for ZL
zl_model = shared_encoder + ZL_prediction_head()
zl_model.fit(zl_specific_data)

# Step 3: Fine-tune for MES  
mes_model = shared_encoder + MES_prediction_head()
mes_model.fit(mes_specific_data)

# Benefit: Shared encoder learns general patterns, heads specialize
```

---

## ğŸ“Š STORAGE FOOTPRINT ESTIMATE

### For Full Dual-Asset Setup:

**ZL Data:**
- Raw: ~20 GB (2000-2025, daily)
- Features: ~5 GB
- Training (5 horizons Ã— 11 regimes): ~10 GB
- Models (30-35 models): ~2 GB
- Predictions/SHAP/Sharpe: ~5 GB
- **Total: ~42 GB**

**MES Data:**
- Raw: ~500 GB (2010-2025, 1-minute tick)
- Features (12 timeframes): ~50 GB
- Training (12 horizons): ~30 GB
- Models (35-40 models): ~3 GB
- Predictions/SHAP/Sharpe: ~10 GB
- **Total: ~593 GB**

**Shared Data:**
- Macro (FRED): ~500 MB
- Regimes: ~100 MB
- Intelligence: ~2 GB
- **Total: ~2.6 GB**

**Meta-Learning:**
- Meta-training tasks: ~5 GB
- Meta-models: ~500 MB
- Adaptation history: ~2 GB
- **Total: ~7.5 GB**

**GRAND TOTAL: ~645 GB**

---

## âœ… ANSWERS TO YOUR QUESTIONS

### 1. How to organize for two primary targets?
**Answer:** SHARED folder for common data (macro, regimes, intelligence) + separate ZL/ and MES/ folders for asset-specific data

### 2. How to keep separate but share datasets?
**Answer:** Layered composition - shared data loaded once, combined with asset-specific data at feature engineering time

### 3. How to micro-train on hyper sets for lower timeframes?
**Answer:** Organize by timeframe granularity - 1min gets 150 micro features, 1d gets 250 macro+fundamental features, separate master_features per timeframe

### 4. How to train for it to learn to learn?
**Answer:** Meta-learning setup - train on all 11 regimes as "tasks," model learns to adapt quickly (5 epochs) to new regimes with minimal data

---

**STATUS:** Research complete  
**NEXT:** Design YOUR specific folder structure with all of this  
**WAITING:** Your approval to proceed with design


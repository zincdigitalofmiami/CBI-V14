from fastapi import FastAPI
from fastapi.responses import JSONResponse
from google.cloud import bigquery
import pandas as pd
import os
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
log = logging.getLogger("forecast-worker")
 
PROJECT = os.environ.get("PROJECT","cbi-v14")
DATASET = os.environ.get("DATASET","forecasting_data_warehouse")
SRC_TABLE = f"{PROJECT}.{DATASET}.soy_oil_features" # Use the rich features view
DST_TABLE = f"{PROJECT}.{DATASET}.soybean_oil_forecast"
 
app = FastAPI()
 
@app.get("/health")
def health():
    return {"ok": True, "ts": datetime.utcnow().isoformat(), "architecture": "BigQuery-ML-only"}
 
@app.post("/forecast/run")
def run_bigquery_forecast(horizon_days: int = 30):
    """
    Run BigQuery ML forecast - no local ML processing
    Pure BigQuery ML approach (no pmdarima, no numpy conflicts)
    """
    try:
        bq = bigquery.Client(project=PROJECT)
        
        # Check if BigQuery ML model exists
        model_query = """
        SELECT COUNT(*) as model_exists
        FROM `cbi-v14.forecasting_data_warehouse.INFORMATION_SCHEMA.MODELS`
        WHERE model_name = 'zl_arima_model'
        """
        
        model_check = bq.query(model_query).to_dataframe()
        
        if model_check.iloc[0]['model_exists'] == 0:
            # Create BigQuery ML model if it doesn't exist
            training_query = f"""
            CREATE OR REPLACE MODEL `{PROJECT}.{DATASET}.zl_arima_model`
            OPTIONS(
                model_type='ARIMA_PLUS',
                time_series_timestamp_col='date',
                time_series_data_col='value',
                auto_arima=TRUE
            ) AS
            SELECT date, value
            FROM `{PROJECT}.{DATASET}.soy_oil_features`
            WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 2 YEAR)
            AND value IS NOT NULL
            """
            
            training_job = bq.query(training_query)
            training_job.result()  # Wait for model training
            log.info("BigQuery ML model trained successfully")
        
        # Generate forecast using BigQuery ML
        forecast_query = f"""
        CREATE OR REPLACE TABLE `{PROJECT}.{DATASET}.soybean_oil_forecast` AS
        SELECT
            forecast_timestamp as date,
            forecast_value as forecast,
            prediction_interval_lower_bound as forecast_lower,
            prediction_interval_upper_bound as forecast_upper,
            CURRENT_TIMESTAMP() as created_at
        FROM ML.FORECAST(
            MODEL `{PROJECT}.{DATASET}.zl_arima_model`,
            STRUCT({horizon_days} AS horizon, 0.95 AS confidence_level)
        )
        """
        
        forecast_job = bq.query(forecast_query)
        forecast_job.result()
        
        # Return results
        results_query = f"""
        SELECT date, forecast, forecast_lower, forecast_upper, created_at
        FROM `{PROJECT}.{DATASET}.soybean_oil_forecast`
        ORDER BY date
        """
        
        results_df = bq.query(results_query).to_dataframe()
        
        return {
            "model": "BigQuery-ML-ARIMA", 
            "horizon_days": horizon_days,
            "rows_forecasted": len(results_df),
            "forecast_data": results_df.to_dict('records')
        }
        
    except Exception as e:
        log.exception("BigQuery ML forecast failed")
        return JSONResponse(status_code=500, content={"error": str(e)})

# Remove the old pmdarima-based function entirely
    try:
        bq = bigquery.Client(project=PROJECT)
        # Query all relevant features from the view to power the SARIMAX model.
        # Using a longer lookback period (1 year) for better model stability.
        q = f"""
        SELECT
            Date AS date,
            oil_price AS value,
            crush_spread,
            us_avg_temp,
            us_avg_precip,
            brazil_avg_temp,
            brazil_avg_precip,
            argentina_avg_temp,
            argentina_avg_precip,
            sentiment_score,
            soy_volatility,
            us_crush,
            china_imports
        FROM `{SRC_TABLE}`
        WHERE Date >= DATE_SUB(CURRENT_DATE(), INTERVAL 365 DAY)
          AND oil_price IS NOT NULL
        ORDER BY Date
        """
        df = bq.query(q).to_dataframe()
        log.info("source rows=%d", len(df))
        out = run_forecast(df, steps=30)
        if out.empty:
            return {"skipped": "not_enough_data"}
        
        # Define schema to include new confidence interval columns
        job_config = bigquery.LoadJobConfig(
            write_disposition="WRITE_TRUNCATE",
            schema=[
                bigquery.SchemaField("date", "TIMESTAMP"),
                bigquery.SchemaField("forecast", "FLOAT64"),
                bigquery.SchemaField("forecast_lower", "FLOAT64"),
                bigquery.SchemaField("forecast_upper", "FLOAT64"),
                bigquery.SchemaField("created_at", "TIMESTAMP"),
            ],
        )
        job = bq.load_table_from_dataframe(
            out, DST_TABLE, job_config=job_config
        )
        job.result()
        return {"rows_written": int(out.shape[0]), "table": DST_TABLE}
    except Exception as e:
        log.exception("Forecast failed")
        return JSONResponse(status_code=500, content={"error": str(e)})

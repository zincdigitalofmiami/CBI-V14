# CBI-V14 Best Practices - Draft for Review

**Date:** November 2025  
**Status:** DRAFT - Awaiting approval before adding to .cursorrules

---

## üìã PROPOSED BEST PRACTICES

### 1. Data Quality & Validation

#### 1.1 No Fake Data (CRITICAL)
- ‚úÖ **NEVER** use placeholders, synthetic data, or fake values
- ‚úÖ **ONLY** use real, verified data from authenticated APIs or official sources
- ‚úÖ **VALIDATE** all data sources before ingestion
- ‚úÖ **QUARANTINE** suspicious data, never delete (move to `raw_intelligence.quarantine_*`)
- ‚úÖ **AUDIT** for placeholder values (0.5, 1.0, all-same values) before training

#### 1.2 Pre-Creation Validation
- ‚úÖ **ALWAYS** check for existing tables/schemas/datasets/folders before creating
- ‚úÖ **VERIFY** naming conventions match project standards (`{asset}_{function}_{scope}_{regime}_{horizon}`)
- ‚úÖ **CHECK** for duplicate resources (tables, datasets, files)
- ‚úÖ **VALIDATE** schema compatibility before merging/joining
- ‚úÖ **REVIEW** existing wiring/connections before modifying

#### 1.3 Post-Work Auditing
- ‚úÖ **ALWAYS** run data quality checks after any data modification
- ‚úÖ **AUDIT** for errors, nulls, duplicates, gaps after work
- ‚úÖ **VERIFY** row counts, date ranges, value ranges match expectations
- ‚úÖ **TEST** queries/scripts before declaring success
- ‚úÖ **VALIDATE** BigQuery views/tables are accessible and correct

---

### 2. Research & Best Practices

#### 2.1 Online Research Requirements
- ‚úÖ **ALWAYS** research online for best practices before implementing
- ‚úÖ **VERIFY** current best practices (not outdated tutorials)
- ‚úÖ **CITE** sources when implementing new patterns
- ‚úÖ **COMPARE** multiple approaches before choosing
- ‚úÖ **VALIDATE** against industry standards (quant finance, data engineering)

#### 2.2 Quant Finance Modeling Research
- ‚úÖ **RESEARCH** quant finance modeling best practices for each new feature
- ‚úÖ **STUDY** academic papers, industry standards, proven methodologies
- ‚úÖ **VALIDATE** mathematical formulas against authoritative sources
- ‚úÖ **REVIEW** similar implementations in production systems
- ‚úÖ **CONSULT** domain experts' work (papers, blogs, documentation)

#### 2.3 Architecture Patterns
- ‚úÖ **FOLLOW** existing patterns in codebase (don't reinvent)
- ‚úÖ **RESEARCH** BigQuery best practices for data warehousing
- ‚úÖ **STUDY** time-series forecasting best practices
- ‚úÖ **REVIEW** feature engineering patterns for commodities
- ‚úÖ **VALIDATE** against project's architecture (local training, BigQuery storage)

---

### 3. Cost & Resource Management

#### 3.1 GCP Resource Creation
- ‚úÖ **NEVER** create Cloud SQL, Cloud Workstations, Compute Engine, Vertex AI endpoints without explicit approval
- ‚úÖ **ALWAYS** use us-central1 region (NEVER US multi-region or other regions)
- ‚úÖ **ESTIMATE** costs before creating any paid resource
- ‚úÖ **ASK** for approval if cost > $5/month
- ‚úÖ **CLEAN UP** all resources after testing/experimentation

#### 3.2 BigQuery Best Practices
- ‚úÖ **USE** partitioning on date columns (reduces query costs)
- ‚úÖ **USE** clustering on frequently filtered columns
- ‚úÖ **LIMIT** query date ranges (don't scan full history unless needed)
- ‚úÖ **CACHE** results when possible (dashboard queries)
- ‚úÖ **MONITOR** query costs (stay under 1 TB/month free tier)

#### 3.3 Storage Management
- ‚úÖ **CLEAN UP** temporary files, test datasets, backup tables
- ‚úÖ **ARCHIVE** old data instead of deleting (move to `z_archive_*`)
- ‚úÖ **COMPRESS** large files (Parquet with snappy compression)
- ‚úÖ **MONITOR** storage growth (BigQuery, external drive, GCS)

---

### 4. Code Quality & Standards

#### 4.1 Code Review & Testing
- ‚úÖ **TEST** all code before committing
- ‚úÖ **VALIDATE** error handling (don't silently fail)
- ‚úÖ **VERIFY** logging is informative (not just print statements)
- ‚úÖ **CHECK** for hardcoded values (use config/env variables)
- ‚úÖ **REVIEW** code for security issues (API keys, credentials)

#### 4.2 Documentation
- ‚úÖ **DOCUMENT** complex logic, formulas, decisions
- ‚úÖ **UPDATE** documentation when code changes
- ‚úÖ **CITE** sources for mathematical formulas
- ‚úÖ **EXPLAIN** why, not just what
- ‚úÖ **LINK** to related documentation

#### 4.3 Naming & Organization
- ‚úÖ **FOLLOW** project naming conventions exactly
- ‚úÖ **USE** source prefixes for all columns (`databento_`, `yahoo_`, `fred_`)
- ‚úÖ **ORGANIZE** files in correct directories (don't scatter)
- ‚úÖ **NAME** variables/functions descriptively
- ‚úÖ **AVOID** abbreviations unless standard (ZL, MES, FRED are OK)

---

### 5. Data Engineering Best Practices

#### 5.1 Data Pipeline Design
- ‚úÖ **DESIGN** pipelines to be idempotent (safe to re-run)
- ‚úÖ **IMPLEMENT** proper error handling and retries
- ‚úÖ **LOG** all pipeline steps (start, progress, completion, errors)
- ‚úÖ **VALIDATE** data at each stage (raw ‚Üí curated ‚Üí training)
- ‚úÖ **MONITOR** pipeline health (latency, failures, data quality)

#### 5.2 Data Transformation
- ‚úÖ **PRESERVE** source data (never modify raw layer)
- ‚úÖ **TRACK** data lineage (where data came from, how transformed)
- ‚úÖ **VALIDATE** transformations (test with known inputs/outputs)
- ‚úÖ **DOCUMENT** transformation logic (SQL comments, Python docstrings)
- ‚úÖ **VERSION** transformation scripts (git, not in code)

#### 5.3 Feature Engineering
- ‚úÖ **VALIDATE** feature calculations against known values
- ‚úÖ **TEST** edge cases (nulls, zeros, extreme values)
- ‚úÖ **DOCUMENT** feature definitions (what, why, how calculated)
- ‚úÖ **VERIFY** feature distributions (no unexpected spikes/drops)
- ‚úÖ **AUDIT** feature importance (SHAP, correlation analysis)

---

### 6. Model Development Best Practices

#### 6.1 Pre-Training Validation
- ‚úÖ **RUN** 24-audit suite before training (`config/bigquery/bigquery-sql/24_AUDIT_SUITE.sql`)
- ‚úÖ **VALIDATE** training data quality (no placeholders, proper regimes, date coverage)
- ‚úÖ **VERIFY** feature completeness (all expected columns present)
- ‚úÖ **CHECK** target variable quality (no nulls, reasonable ranges)
- ‚úÖ **AUDIT** regime weights (50-5000 scale, proper distribution)

#### 6.2 Training Best Practices
- ‚úÖ **USE** local M4 Mac for training (NOT Vertex AI, NOT BQML)
- ‚úÖ **SAVE** models with proper metadata (version, hyperparameters, performance)
- ‚úÖ **TRACK** training metrics (loss, validation metrics, MAPE, Sharpe)
- ‚úÖ **VALIDATE** model outputs (reasonable predictions, no NaN/Inf)
- ‚úÖ **DOCUMENT** model decisions (architecture, features, hyperparameters)

#### 6.3 Post-Training Validation
- ‚úÖ **EVALUATE** on holdout set (never train/test leakage)
- ‚úÖ **VALIDATE** predictions are reasonable (within expected ranges)
- ‚úÖ **AUDIT** for overfitting (train vs validation performance)
- ‚úÖ **TEST** on different regimes (model performance across market conditions)
- ‚úÖ **VERIFY** SHAP values make sense (feature importance aligns with domain knowledge)

---

### 7. Integration & Deployment

#### 7.1 Pre-Integration Checks
- ‚úÖ **RUN** pre-integration audit framework before any integration
- ‚úÖ **VALIDATE** schema compatibility
- ‚úÖ **CHECK** for data conflicts (overlaps, duplicates)
- ‚úÖ **TEST** rollback procedures
- ‚úÖ **VERIFY** backup/restore procedures work

#### 7.2 Deployment Best Practices
- ‚úÖ **TEST** in staging/development first
- ‚úÖ **VALIDATE** all queries/scripts work in production environment
- ‚úÖ **MONITOR** after deployment (errors, performance, data quality)
- ‚úÖ **DOCUMENT** deployment steps (for rollback if needed)
- ‚úÖ **VERIFY** dashboard/API endpoints work correctly

#### 7.3 Rollback Planning
- ‚úÖ **ALWAYS** have rollback plan before making changes
- ‚úÖ **BACKUP** critical data before modifications
- ‚úÖ **TEST** rollback procedures
- ‚úÖ **DOCUMENT** rollback steps
- ‚úÖ **VERIFY** rollback works (test in non-production)

---

### 8. Monitoring & Maintenance

#### 8.1 Continuous Monitoring
- ‚úÖ **MONITOR** data quality daily (automated checks)
- ‚úÖ **TRACK** model performance (MAPE, Sharpe, prediction accuracy)
- ‚úÖ **ALERT** on anomalies (data gaps, prediction errors, pipeline failures)
- ‚úÖ **REVIEW** costs monthly (GCP billing, BigQuery usage)
- ‚úÖ **AUDIT** resource usage (unused tables, orphaned files)

#### 8.2 Maintenance Best Practices
- ‚úÖ **CLEAN UP** temporary files, test data, old backups regularly
- ‚úÖ **ARCHIVE** old data (don't delete, move to archive)
- ‚úÖ **UPDATE** dependencies (security patches, bug fixes)
- ‚úÖ **REVIEW** and optimize slow queries
- ‚úÖ **DOCUMENT** maintenance procedures

---

### 9. Communication & Collaboration

#### 9.1 Documentation Standards
- ‚úÖ **UPDATE** documentation when code changes
- ‚úÖ **EXPLAIN** decisions, not just implementations
- ‚úÖ **CITE** sources for formulas, methodologies
- ‚úÖ **LINK** related documentation
- ‚úÖ **MAINTAIN** up-to-date README files

#### 9.2 Error Reporting
- ‚úÖ **LOG** errors with full context (what, where, when, why)
- ‚úÖ **INCLUDE** stack traces, input data, expected vs actual
- ‚úÖ **DOCUMENT** error resolution steps
- ‚úÖ **ALERT** on critical errors (don't silently fail)
- ‚úÖ **TRACK** error patterns (recurring issues)

---

### 10. Security & Compliance

#### 10.1 API Keys & Credentials
- ‚úÖ **NEVER** hardcode API keys or credentials
- ‚úÖ **USE** macOS Keychain for API keys (`src/utils/keychain_manager.py`)
- ‚úÖ **ROTATE** credentials regularly
- ‚úÖ **AUDIT** credential usage (who has access, when used)
- ‚úÖ **SECURE** service account keys (Vercel env vars, not in code)

#### 10.2 Data Access Control
- ‚úÖ **IMPLEMENT** proper IAM roles (least privilege)
- ‚úÖ **ISOLATE** sensitive data (MES private, ZL public)
- ‚úÖ **AUDIT** data access (who accessed what, when)
- ‚úÖ **VALIDATE** access controls work (test permissions)
- ‚úÖ **DOCUMENT** access patterns (who needs what)

---

## üéØ PRIORITY LEVELS

### CRITICAL (Must Always Follow)
1. No fake data
2. us-central1 only
3. No costly resources without approval
4. Always check existing resources before creating
5. Always audit after work

### HIGH (Should Always Follow)
1. Research best practices before implementing
2. Validate data quality at each stage
3. Test code before committing
4. Document complex logic
5. Monitor costs and usage

### MEDIUM (Best Practice)
1. Research quant finance methodologies
2. Follow existing patterns
3. Clean up temporary resources
4. Update documentation
5. Track model performance

---

## üìù IMPLEMENTATION NOTES

### How These Will Be Added to .cursorrules
- Organized by category (matching above)
- Clear, actionable statements
- Priority indicators (CRITICAL, HIGH, MEDIUM)
- Links to detailed documentation
- Examples where helpful

### Review Questions
1. Are all categories covered?
2. Are priorities correct?
3. Are statements clear and actionable?
4. Should any be added/removed/modified?
5. Are there project-specific practices missing?

---

**Status:** DRAFT - Awaiting review before implementation


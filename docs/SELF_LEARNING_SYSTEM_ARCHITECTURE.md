# SELF-LEARNING PATTERN DISCOVERY SYSTEM
**Date:** October 22, 2025  
**Status:** ARCHITECTURE DEFINED - READY TO IMPLEMENT  
**Question:** "When the neural net finds obscure connections, how will this system record this information and observation and automatically go after more data like it in efforts to 'do deeper'?"

---

## ğŸ¯ ANSWER: THE SELF-LEARNING LOOP

### Current Infrastructure (Clean, Post-Naming-Standardization)

**âœ… CANONICAL TRAINING DATASET:**
- `models.vw_neural_training_dataset` - 1,251 rows Ã— 159 features
- Date range: 2020-10-21 to 2025-10-13
- Targets: 1w, 1m, 3m, 6m horizons
- **This is the ONLY neural training dataset - all v2/v3 variants removed**

**âœ… FEATURE REGISTRY:**
- `forecasting_data_warehouse.feature_metadata` - 29 features documented
- Tracks: feature_name, feature_type, asset_class, economic_meaning, source_table, related_features

**âœ… WORKING PATTERN DETECTION:**
- `vw_price_anomalies` - 65 anomaly records (WORKING)

**âŒ BROKEN PATTERN VIEWS (need fixing):**
- `vw_neural_interaction_features` - References deleted dataset
- `vw_biofuel_bridge_features` - Missing columns
- `vw_elasticity_features` - Missing columns  
- `vw_regime_features` - Missing columns

**âœ… PATTERN DISCOVERY SCRIPTS (exist but reference old names):**
- `scripts/build_neural_obscure_connections.py`
- `scripts/create_biofuel_neural_features.py`

---

## ğŸ”„ THE SELF-LEARNING LOOP ARCHITECTURE

### Phase 1: Training & Explainability Extraction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. MODEL TRAINING (BigQuery ML)                            â”‚
â”‚    â€¢ Train on vw_neural_training_dataset (159 features)    â”‚
â”‚    â€¢ Algorithms: DNN, LightGBM, ARIMA, AutoML              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. EXTRACT MODEL EXPLAINABILITY                             â”‚
â”‚    â€¢ Use ML.EXPLAIN_PREDICT() to get SHAP values           â”‚
â”‚    â€¢ Use ML.FEATURE_IMPORTANCE() to rank features          â”‚
â”‚    â€¢ Log to NEW TABLE: models.model_explainability_log     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TABLE: models.model_explainability_log                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ â€¢ model_name: "zl_dnn_6m_v1"                          â”‚  â”‚
â”‚ â”‚ â€¢ training_date: 2025-10-22                           â”‚  â”‚
â”‚ â”‚ â€¢ feature_name: "feature_biofuel_cascade"             â”‚  â”‚
â”‚ â”‚ â€¢ shap_value_mean: 2.47  â† HIGH IMPORTANCE!           â”‚  â”‚
â”‚ â”‚ â€¢ feature_importance_rank: 3                          â”‚  â”‚
â”‚ â”‚ â€¢ is_obscure_pattern: TRUE  â† Not obvious from theory â”‚  â”‚
â”‚ â”‚ â€¢ confidence_score: 0.89                              â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼ (Automated trigger when is_obscure_pattern=TRUE 
                     AND importance_rank < 10)
```

### Phase 2: Pattern Discovery & Hypothesis Generation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PATTERN DISCOVERY ANALYZER                               â”‚
â”‚    â€¢ Script: discover_obscure_patterns.py (NEW)            â”‚
â”‚    â€¢ Query: SELECT * FROM model_explainability_log         â”‚
â”‚             WHERE is_obscure_pattern = TRUE                 â”‚
â”‚             AND shap_value_mean > threshold                 â”‚
â”‚    â€¢ Identify: Interaction effects, non-linear patterns    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. HYPOTHESIS GENERATION                                    â”‚
â”‚    â€¢ Found: "biofuel_cascade" has high importance          â”‚
â”‚    â€¢ Hypothesis: EPA policy + crush margins + palm price   â”‚
â”‚                  = Strong soy oil price predictor          â”‚
â”‚    â€¢ Log to: models.pattern_discoveries                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TABLE: models.pattern_discoveries                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ â€¢ discovery_id: "disc_20251022_001"                   â”‚  â”‚
â”‚ â”‚ â€¢ discovered_date: 2025-10-22 18:30:00                â”‚  â”‚
â”‚ â”‚ â€¢ pattern_type: "interaction"                         â”‚  â”‚
â”‚ â”‚ â€¢ feature_combo: ["biofuel_policy", "crush_margin",   â”‚  â”‚
â”‚ â”‚                   "palm_oil_price"]                    â”‚  â”‚
â”‚ â”‚ â€¢ strength_score: 0.89                                â”‚  â”‚
â”‚ â”‚ â€¢ hypothesis: "EPA RFS mandates drive soy demand..."  â”‚  â”‚
â”‚ â”‚ â€¢ similar_data_sources: NULL â† TO BE FILLED           â”‚  â”‚
â”‚ â”‚ â€¢ action_status: "pending_data_discovery"             â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
```

### Phase 3: Intelligent Data Source Discovery

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. QUERY FEATURE REGISTRY FOR SIMILAR DATA                  â”‚
â”‚    â€¢ Script: find_similar_data_sources.py (NEW)            â”‚
â”‚    â€¢ Input: pattern_discoveries.feature_combo              â”‚
â”‚    â€¢ Query: forecasting_data_warehouse.feature_metadata    â”‚
â”‚             WHERE economic_meaning SIMILAR TO pattern      â”‚
â”‚    â€¢ Use semantic matching on:                             â”‚
â”‚        - economic_meaning                                  â”‚
â”‚        - related_features                                  â”‚
â”‚        - asset_class                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXAMPLE DISCOVERY:                                          â”‚
â”‚ Pattern: "biofuel_cascade" is important                     â”‚
â”‚ Registry Search: "biofuel" OR "renewable" OR "RIN"          â”‚
â”‚ Results Found:                                              â”‚
â”‚   1. EPA RIN prices (already have âœ…)                       â”‚
â”‚   2. California LCFS credits (MISSING âŒ)                   â”‚
â”‚   3. EU biodiesel mandates (MISSING âŒ)                     â”‚
â”‚   4. Brazilian RenovaBio credits (MISSING âŒ)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. EXPAND FEATURE REGISTRY WITH NEW SOURCES                 â”‚
â”‚    â€¢ Add to feature_metadata:                              â”‚
â”‚      - feature_name: "california_lcfs_credit_price"        â”‚
â”‚      - api_endpoint: "https://ww2.arb.ca.gov/lcfs"         â”‚
â”‚      - query_template: "fetch_lcfs_prices(date_range)"     â”‚
â”‚      - auto_acquire_enabled: TRUE                          â”‚
â”‚      - related_features: ["biofuel_policy", "RIN_price"]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
```

### Phase 4: Automated Data Acquisition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. AUTOMATED DATA INGESTION                                 â”‚
â”‚    â€¢ Script: auto_acquire_similar_data.py (NEW)            â”‚
â”‚    â€¢ For each new source in registry:                      â”‚
â”‚        - Execute api_endpoint + query_template             â”‚
â”‚        - Load to staging.auto_discovered_features          â”‚
â”‚        - Run validation checks                             â”‚
â”‚        - Promote to forecasting_data_warehouse             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. FEATURE ENGINEERING ON NEW DATA                          â”‚
â”‚    â€¢ Script: create_discovered_features.py (NEW)           â”‚
â”‚    â€¢ Create NEW VIEW: vw_discovered_biofuel_features       â”‚
â”‚    â€¢ Calculate: LCFS/RIN spread, policy intensity, etc.    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
```

### Phase 5: Expanded Training & Performance Validation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. EXPAND TRAINING DATASET                                  â”‚
â”‚    â€¢ Create: vw_neural_training_dataset_expanded           â”‚
â”‚    â€¢ Add columns from: vw_discovered_biofuel_features      â”‚
â”‚    â€¢ Now: 159 â†’ 168 features (9 new biofuel features)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. A/B RETRAIN & COMPARE                                   â”‚
â”‚    â€¢ Train model A: Original 159 features                  â”‚
â”‚    â€¢ Train model B: Expanded 168 features                  â”‚
â”‚    â€¢ Compare: MAPE, RMSE, directional accuracy             â”‚
â”‚    â€¢ If Model B wins: Promote to production                â”‚
â”‚    â€¢ If Model A wins: Reject expansion, log failure        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 11. UPDATE PATTERN DISCOVERY LOG                            â”‚
â”‚    â€¢ UPDATE models.pattern_discoveries                     â”‚
â”‚      SET validation_status = 'validated',                  â”‚
â”‚          performance_impact = +0.03  (3% MAPE improvement) â”‚
â”‚          action_status = 'deployed'                        â”‚
â”‚    â€¢ This pattern is now PROVEN ALPHA                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
                LOOP CONTINUES âˆ
```

---

## ğŸ“Š NEW INFRASTRUCTURE REQUIRED

### 1. New BigQuery Tables

```sql
-- Explainability Log
CREATE TABLE `cbi-v14.models.model_explainability_log` (
    model_name STRING,
    training_date DATE,
    feature_name STRING,
    shap_value_mean FLOAT64,
    shap_value_std FLOAT64,
    feature_importance_rank INT64,
    is_obscure_pattern BOOL,
    confidence_score FLOAT64,
    logged_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP()
);

-- Pattern Discoveries
CREATE TABLE `cbi-v14.models.pattern_discoveries` (
    discovery_id STRING,
    discovered_date TIMESTAMP,
    pattern_type STRING,  -- 'correlation', 'interaction', 'regime', 'anomaly'
    feature_combo ARRAY<STRING>,
    strength_score FLOAT64,
    hypothesis STRING,
    similar_data_sources ARRAY<STRING>,
    action_status STRING,  -- 'pending', 'data_acquired', 'deployed', 'rejected'
    validation_status STRING,  -- 'candidate', 'validated', 'rejected'
    performance_impact FLOAT64,  -- MAPE improvement or NULL if not deployed
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),
    updated_at TIMESTAMP
);

-- Auto-Discovered Features (Staging)
CREATE TABLE `cbi-v14.staging.auto_discovered_features` (
    source_name STRING,
    feature_name STRING,
    date DATE,
    value FLOAT64,
    metadata JSON,
    discovered_from_pattern_id STRING,
    ingested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP()
);
```

### 2. Extend Feature Metadata (Additive Only)

```sql
-- Add columns to EXISTING table
ALTER TABLE `cbi-v14.forecasting_data_warehouse.feature_metadata`
ADD COLUMN IF NOT EXISTS api_endpoint STRING,
ADD COLUMN IF NOT EXISTS query_template STRING,
ADD COLUMN IF NOT EXISTS similar_features ARRAY<STRING>,
ADD COLUMN IF NOT EXISTS auto_acquire_enabled BOOL DEFAULT FALSE,
ADD COLUMN IF NOT EXISTS discovery_priority INT64;  -- 1=high, 5=low
```

### 3. New Python Scripts

```
scripts/
â”œâ”€â”€ extract_model_explainability.py      (NEW) - Extract SHAP after training
â”œâ”€â”€ discover_obscure_patterns.py         (NEW) - Analyze explainability log
â”œâ”€â”€ find_similar_data_sources.py         (NEW) - Query registry for similar
â”œâ”€â”€ auto_acquire_similar_data.py         (NEW) - Fetch data from APIs
â”œâ”€â”€ create_discovered_features.py        (NEW) - Engineer features from new data
â”œâ”€â”€ expand_training_dataset.py           (NEW) - Add new features to training
â”œâ”€â”€ compare_model_performance.py         (NEW) - A/B test old vs new
â””â”€â”€ orchestrate_learning_loop.py         (NEW) - Master coordinator
```

### 4. Update Existing Scripts (Fix Broken References)

```
BROKEN VIEWS TO FIX:
- vw_neural_interaction_features â†’ Update to reference vw_neural_training_dataset (not v2)
- vw_biofuel_bridge_features â†’ Fix missing column references
- vw_elasticity_features â†’ Fix missing column references
- vw_regime_features â†’ Fix missing column references

SCRIPTS TO UPDATE:
- build_neural_obscure_connections.py â†’ Update dataset references
- create_biofuel_neural_features.py â†’ Update dataset references
```

---

## ğŸ”¥ EXAMPLE: FULL LOOP IN ACTION

### Iteration 1: Discovering Biofuel Pattern

```
1. Train zl_dnn_6m_v1 on 159 features
   â†“
2. Extract SHAP values
   â†“ Find: "feature_biofuel_cascade" ranks #3 (unexpected!)
   â†“
3. Log to model_explainability_log
   â†“ is_obscure_pattern=TRUE (not obvious from commodity fundamentals)
   â†“
4. Pattern discovery script triggers
   â†“ Hypothesis: "Biofuel policy mandates drive soy oil demand"
   â†“
5. Query feature_metadata for similar data
   â†“ Find: EPA RIN prices (have âœ…), CA LCFS (missing âŒ), EU mandates (missing âŒ)
   â†“
6. Auto-acquire script pulls CA LCFS credit prices
   â†“ Load to staging.auto_discovered_features
   â†“
7. Create vw_discovered_lcfs_features (new view)
   â†“ Features: lcfs_price, lcfs_rin_spread, policy_intensity
   â†“
8. Expand training dataset: 159 â†’ 162 features
   â†“
9. Retrain: Model A (159) vs Model B (162)
   â†“ Model B MAPE: 4.2% | Model A MAPE: 4.5%
   â†“ Model B WINS by 0.3% (7% relative improvement)
   â†“
10. Deploy Model B, update pattern_discoveries
    â†“ validation_status='validated', performance_impact=+0.003
    â†“
LOOP COMPLETE - New features permanently added
```

### Iteration 2: System Goes Deeper

```
Now the system looks for patterns in the NEW features:
- Does LCFS price interact with crush margins?
- Does LCFS/RIN spread predict volatility regimes?
- Should we get state-level biodiesel mandates?

The loop NEVER STOPS discovering and improving.
```

---

## âš ï¸ CRITICAL SAFEGUARDS

### 1. Cost Control
- Set `auto_acquire_enabled=FALSE` by default
- Require human approval for new API endpoints
- Budget cap: $50/month for experimental data

### 2. Performance Validation
- NEVER deploy expanded model if performance degrades
- Require minimum 2% relative MAPE improvement
- Backtest on held-out data before production

### 3. Pattern Decay Tracking
- Monitor pattern strength over rolling windows
- Auto-disable features if importance drops below threshold
- Re-validate patterns quarterly

### 4. Data Quality Gates
- Validate new data for completeness, freshness, outliers
- Reject sources with >10% missing data
- Require manual review for non-numeric data

---

## ğŸ“ˆ EXPECTED OUTCOMES

### Short Term (1-2 weeks)
- 4 broken views fixed
- Explainability extraction working
- Pattern discovery logging operational

### Medium Term (1 month)
- First automated data source added
- Training dataset expanded by 5-10 features
- Measurable MAPE improvement from discovered patterns

### Long Term (3-6 months)
- 20+ new features discovered and validated
- Self-learning loop runs weekly without human intervention
- System discovers non-obvious interactions (e.g., freight costs Ã— weather Ã— biofuel policy)
- Platform becomes "smarter" with every training cycle

---

## âœ… NEXT STEPS TO IMPLEMENT

### Phase 1: Fix & Monitor (This Week)
1. âœ… Document current state (DONE - this file)
2. Fix 4 broken pattern views
3. Create explainability extraction script
4. Test SHAP value extraction on existing models

### Phase 2: Discovery Infrastructure (Week 2)
5. Create pattern_discoveries table
6. Build pattern discovery analyzer
7. Enhance feature_metadata with API fields
8. Test similar-data-finder on existing registry

### Phase 3: Automation (Week 3-4)
9. Build data acquisition framework
10. Create feature engineering automation
11. Implement A/B testing framework
12. Deploy orchestrator for full loop

**THIS IS HOW THE SYSTEM GETS SMARTER AUTOMATICALLY.**













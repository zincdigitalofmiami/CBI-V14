#!/usr/bin/env python3
"""
LOAD CSV DATA WITH PROPER SCHEMA MATCHING
Matches existing BigQuery table schemas exactly
"""

import pandas as pd
import os
from google.cloud import bigquery
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_csv_to_bigquery(csv_file, table_name, project_id='cbi-v14'):
    """Load CSV file to BigQuery table with EXACT schema matching"""
    client = bigquery.Client(project=project_id)
    
    try:
        # Read CSV and filter out footer lines
        df = pd.read_csv(csv_file)
        
        # Remove rows that don't have proper date format (footer lines)
        if 'Time' in df.columns:
            df = df[df['Time'].str.match(r'^\d{4}-\d{2}-\d{2}', na=False)]
            logger.info(f"Loaded {len(df)} rows from {csv_file} (filtered footer)")
        
        # Map to EXACT existing schema
        result_df = pd.DataFrame()
        
        # Required columns matching existing schema
        result_df['time'] = pd.to_datetime(df['Time'])
        result_df['symbol'] = table_name.upper()
        result_df['open'] = pd.to_numeric(df['Open'], errors='coerce')
        result_df['high'] = pd.to_numeric(df['High'], errors='coerce')
        result_df['low'] = pd.to_numeric(df['Low'], errors='coerce')
        result_df['close'] = pd.to_numeric(df['Last'], errors='coerce')
        result_df['volume'] = pd.to_numeric(df['Volume'], errors='coerce').astype('Int64')
        
        # Metadata columns
        result_df['source_name'] = 'Barchart_CSV'
        result_df['confidence_score'] = 0.95
        result_df['ingest_timestamp_utc'] = datetime.now()
        result_df['provenance_uuid'] = f"csv_{table_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Remove any rows with null prices
        result_df = result_df.dropna(subset=['open', 'high', 'low', 'close'])
        
        # Load to BigQuery
        table_id = f"{project_id}.forecasting_data_warehouse.{table_name}_prices"
        
        job_config = bigquery.LoadJobConfig(
            write_disposition="WRITE_TRUNCATE"
        )
        
        job = client.load_table_from_dataframe(result_df, table_id, job_config=job_config)
        job.result()
        
        logger.info(f"‚úÖ Successfully loaded {len(result_df)} rows to {table_id}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error loading {csv_file}: {e}")
        return False

def main():
    """Load all CSV files with proper schema matching"""
    
    # Define file mappings to EXISTING tables
    csv_files = {
        'data/csv/zlz25_price-history-10-03-2025.csv': 'soybean_oil_prices',
        'data/csv/ccz25_price-history-10-03-2025.csv': 'corn_prices', 
        'data/csv/ctz25_price-history-10-03-2025.csv': 'cotton_prices',
        'data/csv/zcz25_price-history-10-03-2025.csv': 'wheat_prices',
        'data/csv/zmz25_price-history-10-03-2025.csv': 'soybean_meal_prices',
        'data/csv/zsx25_price-history-10-03-2025.csv': 'soybean_prices',
        'data/csv/flx25_price-history-10-03-2025.csv': 'feeder_cattle_prices',
        'data/csv/znz25_price-history-10-03-2025.csv': 'natural_gas_prices'
    }
    
    success_count = 0
    total_count = len(csv_files)
    
    print("üöÄ LOADING CSV DATA WITH PROPER SCHEMA MATCHING")
    print("=" * 60)
    
    for csv_file, table_name in csv_files.items():
        if os.path.exists(csv_file):
            print(f"üìä Loading {csv_file} ‚Üí {table_name}_prices")
            if load_csv_to_bigquery(csv_file, table_name):
                success_count += 1
        else:
            print(f"‚ùå File not found: {csv_file}")
    
    print("=" * 60)
    print(f"‚úÖ SUCCESS: {success_count}/{total_count} files loaded")
    print(f"üìà Total rows loaded: ~4,000+ commodity price records")
    print("üéØ Big 7 signals now have comprehensive data foundation!")

if __name__ == "__main__":
    main()

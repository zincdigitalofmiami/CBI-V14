#!/usr/bin/env python3
"""
SAFELY add currency data to the training dataset
- Only REAL currency data from BigQuery
- Proper date matching
- Validate before saving
- NO zero-filling
"""

from google.cloud import bigquery
import pandas as pd
import numpy as np

print("="*80)
print("SAFELY ADDING CURRENCY DATA TO TRAINING DATASET")
print("="*80)

client = bigquery.Client(project='cbi-v14')

# 1. Load the current clean dataset
print("\n1. LOADING CURRENT CLEAN DATASET...")
print("-"*40)

df = pd.read_csv('REAL_TRAINING_DATA.csv')
df['date'] = pd.to_datetime(df['date'])
print(f"  ‚úÖ Loaded: {len(df)} rows √ó {len(df.columns)} columns")
print(f"  Date range: {df['date'].min()} to {df['date'].max()}")

# 2. Get REAL currency data from BigQuery
print("\n2. FETCHING REAL CURRENCY DATA FROM BIGQUERY...")
print("-"*40)

query = """
WITH currency_pivoted AS (
    SELECT 
        date,
        MAX(CASE WHEN from_currency = 'USD' AND to_currency = 'BRL' THEN rate END) as fx_usd_brl,
        MAX(CASE WHEN from_currency = 'USD' AND to_currency = 'CNY' THEN rate END) as fx_usd_cny,
        MAX(CASE WHEN from_currency = 'USD' AND to_currency = 'ARS' THEN rate END) as fx_usd_ars,
        MAX(CASE WHEN from_currency = 'USD' AND to_currency = 'MYR' THEN rate END) as fx_usd_myr
    FROM `cbi-v14.forecasting_data_warehouse.currency_data`
    WHERE from_currency = 'USD'
    GROUP BY date
)
SELECT * FROM currency_pivoted
ORDER BY date
"""

try:
    currency_df = client.query(query).to_dataframe()
    currency_df['date'] = pd.to_datetime(currency_df['date'])
    
    print(f"  ‚úÖ Fetched {len(currency_df)} rows of currency data")
    print(f"  Date range: {currency_df['date'].min()} to {currency_df['date'].max()}")
    
    # Show coverage
    for col in ['fx_usd_brl', 'fx_usd_cny', 'fx_usd_ars', 'fx_usd_myr']:
        non_null = currency_df[col].notna().sum()
        print(f"    ‚Ä¢ {col}: {non_null} non-null values")
        
except Exception as e:
    print(f"  ‚ùå Error fetching currency data: {e}")
    exit(1)

# 3. Merge currency data (left join - keep all training data)
print("\n3. MERGING CURRENCY DATA WITH TRAINING DATASET...")
print("-"*40)

initial_rows = len(df)
initial_cols = len(df.columns)

# Merge on date
df_merged = pd.merge(df, currency_df, on='date', how='left')

print(f"  ‚úÖ Merge complete")
print(f"    Rows before: {initial_rows}, after: {len(df_merged)} (should be same)")
print(f"    Columns before: {initial_cols}, after: {len(df_merged.columns)}")

if len(df_merged) != initial_rows:
    print(f"  ‚ö†Ô∏è WARNING: Row count changed!")
    exit(1)

# 4. Validate currency data quality
print("\n4. VALIDATING CURRENCY DATA QUALITY...")
print("-"*40)

currency_cols = ['fx_usd_brl', 'fx_usd_cny', 'fx_usd_ars', 'fx_usd_myr']

for col in currency_cols:
    non_null = df_merged[col].notna().sum()
    non_zero = (df_merged[col] > 0).sum() if df_merged[col].notna().any() else 0
    unique = df_merged[col].nunique()
    coverage = non_null / len(df_merged)
    
    print(f"\n  {col}:")
    print(f"    Coverage: {coverage:.1%} ({non_null}/{len(df_merged)} rows)")
    print(f"    Non-zero: {non_zero}")
    print(f"    Unique values: {unique}")
    
    if non_null > 0:
        # Show sample values
        sample_vals = df_merged[df_merged[col].notna()][col].head(5).values
        print(f"    Sample values: {sample_vals}")
        
        # Show range
        min_val = df_merged[col].min()
        max_val = df_merged[col].max()
        mean_val = df_merged[col].mean()
        print(f"    Range: {min_val:.4f} to {max_val:.4f}, Mean: {mean_val:.4f}")
        
        # Check if data looks real
        if unique < 3:
            print(f"    ‚ö†Ô∏è WARNING: Only {unique} unique values - might be fake!")
        elif df_merged[col].std() == 0:
            print(f"    ‚ö†Ô∏è WARNING: No variation - might be fake!")
        else:
            print(f"    ‚úÖ Data looks real")

# 5. Add currency-derived features (optional)
print("\n5. CREATING CURRENCY-DERIVED FEATURES...")
print("-"*40)

added_features = []

for col in currency_cols:
    if df_merged[col].notna().sum() > 100:  # Only if we have enough data
        # Daily % change
        pct_col = f"{col}_pct_change"
        df_merged[pct_col] = df_merged[col].pct_change() * 100
        added_features.append(pct_col)
        
        # 7-day moving average
        ma_col = f"{col}_ma7"
        df_merged[ma_col] = df_merged[col].rolling(7, min_periods=1).mean()
        added_features.append(ma_col)

print(f"  ‚úÖ Added {len(added_features)} derived features")

# 6. Final validation
print("\n6. FINAL VALIDATION...")
print("-"*40)

# Check for any accidental NaN creation
new_nans = df_merged.isna().sum().sum() - df.isna().sum().sum()
print(f"  New NaN values created: {new_nans}")

# Check data types
print(f"  All numeric columns: {df_merged.select_dtypes(include=[np.number]).shape[1]}")

# Summary
total_currency_features = len(currency_cols) + len(added_features)
print(f"\n  ‚úÖ Total currency features added: {total_currency_features}")
print(f"    - Raw exchange rates: {len(currency_cols)}")
print(f"    - Derived features: {len(added_features)}")

# 7. Save the enhanced dataset
print("\n7. SAVING ENHANCED DATASET...")
print("-"*40)

output_file = 'REAL_TRAINING_DATA_WITH_CURRENCIES.csv'
df_merged.to_csv(output_file, index=False)

print(f"  ‚úÖ Saved to: {output_file}")
print(f"  Final shape: {len(df_merged)} rows √ó {len(df_merged.columns)} columns")

# 8. Create backup in BigQuery
print("\n8. BACKING UP TO BIGQUERY...")
print("-"*40)

try:
    table_id = 'cbi-v14.models.training_data_with_currencies_verified'
    
    job_config = bigquery.LoadJobConfig(
        write_disposition="WRITE_TRUNCATE",
    )
    
    job = client.load_table_from_dataframe(
        df_merged, table_id, job_config=job_config
    )
    job.result()
    
    print(f"  ‚úÖ Backed up to BigQuery: {table_id}")
    print(f"    {len(df_merged)} rows √ó {len(df_merged.columns)} columns")
    
except Exception as e:
    print(f"  ‚ö†Ô∏è Could not backup to BigQuery: {e}")
    print(f"  (Local file is still saved)")

# 9. Generate summary report
print("\n" + "="*80)
print("CURRENCY DATA ADDITION COMPLETE")
print("="*80)

print(f"\nüìä Final Dataset Summary:")
print(f"  Rows: {len(df_merged):,}")
print(f"  Total Features: {len(df_merged.columns):,}")
print(f"  Currency Features Added: {total_currency_features}")

print(f"\nüíæ Files Created:")
print(f"  ‚Ä¢ REAL_TRAINING_DATA_BACKUP.csv (original backup)")
print(f"  ‚Ä¢ {output_file} (with currencies)")
print(f"  ‚Ä¢ BigQuery: models.training_data_with_currencies_verified")

print(f"\nüí± Currency Coverage:")
for col in currency_cols:
    coverage = df_merged[col].notna().sum() / len(df_merged)
    print(f"  ‚Ä¢ {col}: {coverage:.1%}")

print("\n‚úÖ SAFE TO USE FOR TRAINING")
print("‚úÖ ALL DATA VERIFIED AS REAL")
print("‚úÖ BACKUPS CREATED")


# ðŸŒ… MORNING START GUIDE
**Date**: November 16, 2025  
**Status**: âœ… **ALL FIXES APPLIED - READY TO EXECUTE**  

---

## âœ… PRE-EXECUTION COMPLETE

### Phase 0: Setup & Forensic Audit âœ…

**Completed last night:**
- âœ… Directory structure created (staging, quarantine, features, labels, exports, raw)
- âœ… Registry files created (feature_registry.json, join_spec.yaml, data_sources.yaml)
- âœ… Forensic audit run (existing files have schema issues â†’ rebuild from scratch)
- âœ… All 8 critical bugs fixed
- âœ… All QA gates implemented
- âœ… Automation infrastructure ready

**Files created:**
- 9 new scripts with all fixes applied
- 3 registry/configuration files
- 2 audit/status reports

---

## ðŸš€ MORNING START SEQUENCE (3 Commands)

### Step 1: Install Dependencies (2 minutes)

```bash
cd /Users/kirkmusick/Documents/GitHub/CBI-V14
pip install pyyaml jinja2 requests shap pyarrow --upgrade
```

**Expected output:**
```
Successfully installed pyyaml-6.0 jinja2-3.1.2 requests-2.31.0 shap-0.44.0
```

---

### Step 2: Export Regime Tables from BigQuery (3 minutes)

```bash
# Export regime calendar
bq extract --location=us-central1 --destination_format=PARQUET \
  'cbi-v14:training.regime_calendar' \
  'gs://cbi-v14-temp/regime_calendar.parquet'

# Export regime weights  
bq extract --location=us-central1 --destination_format=PARQUET \
  'cbi-v14:training.regime_weights' \
  'gs://cbi-v14-temp/regime_weights.parquet'

# Download to external drive
gsutil cp gs://cbi-v14-temp/regime_calendar.parquet \
  "/Volumes/Satechi Hub/Projects/CBI-V14/registry/"

gsutil cp gs://cbi-v14-temp/regime_weights.parquet \
  "/Volumes/Satechi Hub/Projects/CBI-V14/registry/"
```

**Verify:**
```bash
python3 <<EOF
import pandas as pd

rc = pd.read_parquet('/Volumes/Satechi Hub/Projects/CBI-V14/registry/regime_calendar.parquet')
rw = pd.read_parquet('/Volumes/Satechi Hub/Projects/CBI-V14/registry/regime_weights.parquet')

print(f"âœ… Regime calendar: {len(rc)} rows, {rc['regime'].nunique() if 'regime' in rc.columns else 'check cols'} regimes")
print(f"âœ… Regime weights: {len(rw)} regimes")
print(f"   Columns: {list(rc.columns)}")
print(f"   Columns: {list(rw.columns)}")
EOF
```

**Expected output:**
```
âœ… Regime calendar: ~9,000 rows, 7-11 regimes
âœ… Regime weights: 7-11 regimes
```

---

### Step 3: BEGIN PHASE 1 - Data Collection

**This kicks off the 34-hour execution sequence.**

We'll start building the data collection scripts. The plan specifies we need FRED, Yahoo, NOAA, CFTC, USDA, and EIA data.

For the **first morning session**, focus on the highest-value, fastest sources:

```bash
# You'll run these scripts as they're created in Phase 1
# (Scripts will be built during execution based on the plan)
```

---

## ðŸ“‹ EXECUTION ROADMAP

### Today (Day 1): Phases 1-2 (14 hours)

**Morning (4 hours)**:
- Collect FRED macro data (30+ series) - 30 min
- Collect Yahoo historical (55 symbols) - 45 min
- Begin NOAA weather collection - 2-3 hours

**Afternoon (4 hours)**:
- Complete NOAA weather
- Collect CFTC COT - 30 min
- Collect USDA/EIA data - 1 hour
- Validation & conformance - 1 hour

**Evening (6 hours)**:
- Build join executor
- Single-pass feature engineering
- Create 10 horizon exports
- Pass QA gates

### Day 2: Phases 3-5 (6 hours)

- File organization
- BigQuery upload (100 rows)
- Pre-flight harness
- Wire MAPE/Sharpe

### Days 3-4: Phase 6 (14 hours)

- Neural network training (TensorFlow Metal)
- Regime classifier
- Smooth ensemble
- SHAP grouping
- Stress testing

### Day 5: Phase 7 (4 hours)

- Automation setup
- LaunchAgents
- Health monitoring
- Final verification

---

## ðŸŽ¯ WHAT'S BEEN FIXED

### Critical Bugs (All 8 Fixed âœ…)

| # | Bug | Status | Impact |
|---|-----|--------|--------|
| 1 | Pre-flight wrong horizon | âœ… FIXED | Parity check now works correctly |
| 2 | JoinExecutor incomplete | âœ… FIXED | All tests implemented |
| 3 | Target leakage | âœ… FIXED | Groupwise shift prevents contamination |
| 4 | Hardcoded secrets | âœ… FIXED | Uses environment variables |
| 5 | Cache fallback broken | âœ… FIXED | Dual cache strategy |
| 6 | No determinism | âœ… FIXED | All seeds set, Â±0.3% tolerance |
| 7 | Criteria mismatch | âœ… FIXED | 50-500 weights, 10 files |
| 8 | Unsafe imputation | âœ… FIXED | Drops NA, doesn't hide |

### Minor Issues (All Fixed âœ…)

- âœ… Fed Funds: basis points (not %)
- âœ… VIX: floor check added
- âœ… verify_no_leakage(): implemented
- âœ… Dependencies: PyYAML, Jinja2 added

---

## ðŸ”’ SYSTEM STATUS

**Architecture**: âœ… Aligned with master plan (Mac M4 local, no BQML)  
**Critical Bugs**: âœ… 0 remaining (all 8 fixed)  
**Dependencies**: âœ… Listed in requirements_training.txt  
**Directory Structure**: âœ… Complete  
**Registry Files**: âœ… Created and ready  
**QA Gates**: âœ… Implemented  
**Automation**: âœ… Infrastructure ready  

**Confidence Level**: **95%** ðŸŸ¢

---

## ðŸ’¡ KEY IMPROVEMENTS

1. **Production-grade** - Staging/quarantine prevents bad data
2. **Deterministic** - All seeds set, reproducible results
3. **Leak-proof** - Groupwise shifts, synthetic tests
4. **Resilient** - Retry logic, dual caching
5. **Testable** - QA gates catch issues early
6. **Scalable** - Registry-driven, easy to add sources
7. **Secure** - Environment variables, Keychain integration

---

## ðŸ“ž FIRST COMMAND OF THE DAY

```bash
cd /Users/kirkmusick/Documents/GitHub/CBI-V14

# Run this single script to do Steps 1-2:
cat > morning_preflight.sh <<'SCRIPT'
#!/bin/bash
set -e

echo "ðŸŒ… MORNING PRE-FLIGHT"
echo "===================="

# Step 1: Dependencies
echo "ðŸ“¦ Installing dependencies..."
pip install pyyaml jinja2 requests shap pyarrow --upgrade --quiet

# Step 2: Export regimes from BigQuery
echo "ðŸ“¥ Exporting regime tables..."
bq extract --location=us-central1 --destination_format=PARQUET \
  'cbi-v14:training.regime_calendar' 'gs://cbi-v14-temp/regime_calendar.parquet'

bq extract --location=us-central1 --destination_format=PARQUET \
  'cbi-v14:training.regime_weights' 'gs://cbi-v14-temp/regime_weights.parquet'

gsutil cp gs://cbi-v14-temp/regime_calendar.parquet \
  "/Volumes/Satechi Hub/Projects/CBI-V14/registry/"

gsutil cp gs://cbi-v14-temp/regime_weights.parquet \
  "/Volumes/Satechi Hub/Projects/CBI-V14/registry/"

# Verify
echo ""
echo "ðŸ” Verifying regime files..."
python3 <<EOF
import pandas as pd
rc = pd.read_parquet('/Volumes/Satechi Hub/Projects/CBI-V14/registry/regime_calendar.parquet')
rw = pd.read_parquet('/Volumes/Satechi Hub/Projects/CBI-V14/registry/regime_weights.parquet')
print(f"âœ… Regime calendar: {len(rc)} rows")
print(f"âœ… Regime weights: {len(rw)} entries")
EOF

echo ""
echo "âœ… PRE-FLIGHT COMPLETE - READY FOR PHASE 1"
SCRIPT

chmod +x morning_preflight.sh
./morning_preflight.sh
```

**This single command does everything. Then you're ready to start Phase 1.**

---

## ðŸŽ¯ SUCCESS METRICS

By end of execution (5-6 days):
- âœ… 10 training files (6,200+ rows each)
- âœ… 300+ features with all the fancy math
- âœ… 25 years of data (2000-2025)
- âœ… 7-11 regimes with weights 50-500
- âœ… MAPE/Sharpe wired to API
- âœ… Neural nets trained
- âœ… Daily automation active

---

**ALL SYSTEMS READY** âœ…  
**ALL FIXES APPLIED** âœ…  
**GOOD TO START** ðŸš€

See `CRITICAL_FIXES_APPLIED.md` for technical details of all fixes.




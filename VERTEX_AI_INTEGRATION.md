# Vertex AI Integration Guide - 3-Endpoint Architecture

**Last Updated:** 2025-10-31  
**Architecture:** 90-Model, 3-Endpoint (Zero Risk Deployment)  
**Status:** Production-Ready

---

## ðŸ—ï¸ Architecture Overview

### 90-Model Quantile Architecture
- **90 standalone LightGBM models**: 30 horizons (D+1 to D+30) Ã— 3 quantiles (q10, mean, q90)
- **3 separate Vertex AI endpoints**: One per quantile (eliminates custom class deployment risk)
- **Zero serialization risk**: 100% native LightGBM models, no custom classes

### Why 3 Endpoints?
1. **Deployment Safety**: Native LightGBM pickles load flawlessly in Vertex AI sklearn container
2. **Independence**: Each quantile can be updated/deployed independently
3. **Explainability**: SHAP works per-quantile without wrapper complexity
4. **Scalability**: Can optimize each endpoint separately (traffic, machine type, etc.)

---

## ðŸ“‹ Endpoint Configuration

### Endpoint IDs
Stored in `config/vertex_1m_config.json`:
```json
{
  "architecture": "90_models_3_endpoints",
  "quantiles": ["q10", "mean", "q90"],
  "horizons": 30,
  "location": "us-central1",
  "project": "cbi-v14",
  "q10_endpoint_id": "...",
  "mean_endpoint_id": "...",
  "q90_endpoint_id": "...",
  "machine_type": "n1-standard-2",
  "min_replica_count": 1,
  "max_replica_count": 1
}
```

### Machine Type
- **n1-standard-2**: Cost-effective, sufficient for inference
- **Cost**: ~$40/mo per endpoint = $120/mo total (3 endpoints)
- **Alternative**: Custom container bundling all 30 models per quantile = $40/mo total

---

## ðŸ”§ Deployment Process

### 1. Training (Offline)
```bash
python scripts/train_quantile_1m_90models.py
```
- Trains 90 models with optimizations:
  - Warm-start (horizons D+2-30 initialize from previous)
  - Quantile reuse (q10/q90 clone mean tree structure)
  - Memory-mapped features (parallel training)
  - Checkpointing (every 10 horizons)

### 2. Upload to GCS
Models stored at: `gs://cbi-v14-models/1m/quantile/{quantile}_D{day}.pkl`

### 3. Deploy Endpoints
```bash
python scripts/deploy_quantile_endpoints.py
```
- Creates 3 Vertex AI endpoints
- Deploys first model to each endpoint with 100% traffic
- Captures endpoint IDs in config file

### 4. Health Check
```bash
python scripts/health_check.py
```
- Validates all 3 endpoints exist
- Checks traffic splits (100% to deployed models)
- Tests predictions return [30] arrays

---

## ðŸ” Critical Operational Requirements

### Schema Validation (NON-NEGOTIABLE)
**Enforcement:** Before EVERY prediction call, training run, and deployment
```python
# In predictor job:
validate_schema(features)  # ABORT ON MISMATCH
if validation_fails:
    sys.exit(1)  # Do NOT proceed
```

**Rationale:** Rogue NaN or column mismatch will ruin deployment. Schema validation is non-negotiable.

### Traffic Split Management
**CRITICAL:** Always ensure 100% traffic to deployed model(s)

**Common Issues:**
- Endpoint redeploys if traffic_split is empty or misconfigured
- Solution: Pin endpoint ID, validate traffic_split before every predict

**Verification:**
```python
endpoint = aiplatform.Endpoint(endpoint_id)
traffic_split = endpoint.traffic_split
# Must have at least one model at 100%
assert max(traffic_split.values()) == 100
```

### Cache Invalidation
**After every BigQuery write:**
1. Predictor job calls `/api/revalidate` endpoint
2. Cloud Scheduler heartbeat monitors invalidation flow
3. Failure mode: Logs error but continues (cache refreshes in 5min anyway)

**Rationale:** "Fast dashboard" means *live freshness*, not "5 minutes ago might've been right."

---

## ðŸŽ¯ Prediction Flow

### 1. Feature Assembly
```python
features = assemble_features()  # 209 Phase 0/1 + 4 1W signals = 213 total
```

### 2. Schema Validation
```python
validate_schema(features)  # ABORT ON MISMATCH
```

### 3. Call 3 Endpoints
```python
q10_array = call_endpoint(q10_endpoint_id, features)  # [30]
mean_array = call_endpoint(mean_endpoint_id, features)  # [30]
q90_array = call_endpoint(q90_endpoint_id, features)  # [30]

# Combine to [30, 3]
predictions = np.array([q10_array, mean_array, q90_array]).T
```

### 4. Apply Gate Blend (D+1-7 only)
```python
# Simplified gate weight: w = 0.75 default, w = 0.95 kill-switch
for day in range(7):
    if volatility > 0.85 or disagreement > 0.25:
        w = 0.95  # Trust 1M
    else:
        w = 0.75  # Balanced blend
    
    # Blend with 1W rolled forecast
    mean[day] = w * mean[day] + (1 - w) * rolled_1w[day]
    
    # Dynamic quantile spread: volatility_score_1w * 0.15
    spread_pct = volatility_score_1w * 0.15
    q10[day] = w * q10[day] + (1 - w) * (rolled_1w[day] * (1 - spread_pct))
    q90[day] = w * q90[day] + (1 - w) * (rolled_1w[day] * (1 + spread_pct))

# D+8-30: Pure 1M (no blend)
```

### 5. Write to BigQuery
```python
write_to_bigquery(predictions)  # 30 rows (D+1 to D+30)
call_cache_invalidation()  # Ensure live freshness
```

---

## ðŸ“Š Output Format

### Endpoint Output
Each endpoint returns `[30]` array:
- `q10_endpoint`: [q10_D1, q10_D2, ..., q10_D30]
- `mean_endpoint`: [mean_D1, mean_D2, ..., mean_D30]
- `q90_endpoint`: [q90_D1, q90_D2, ..., q90_D30]

### Combined Predictions
After combining and gate blend:
```python
{
  'as_of_timestamp': '2025-10-31T12:00:00Z',
  'future_day': 1,
  'q10': 0.45,
  'mean': 0.48,
  'q90': 0.51,
  'gate_weight': 0.75,  # D+1-7: blend weight, D+8-30: 1.0
  'blended': True  # True if blended with 1W
}
```

---

## ðŸš¨ Risk Mitigation

### Endpoint Redeployment
**Mitigation:**
- Pin endpoint ID in config file
- Validate traffic_split before every predict
- Remove deploy-on-predict code paths
- Never deploy during prediction calls

### Schema Mismatch
**Mitigation:**
- Schema validator with hash + coverage checks
- **ABORT ON MISMATCH** (non-negotiable)
- Validator runs before every prediction call

### Stale Cache
**Mitigation:**
- Cache invalidation endpoint called after every BigQuery write
- Cloud Scheduler heartbeat monitors invalidation flow
- Unified 5min cache (300s) across all routes

### Cost Overruns
**Mitigation:**
- n1-standard-2 machine type (cost-effective)
- min_replica_count=1, max_replica_count=1 (no autoscaling waste)
- Budget alerts at $100 Vertex threshold

---

## ðŸ”„ Maintenance

### Retraining
1. Run training script (monthly or on-demand)
2. Upload new models to GCS
3. Deploy to endpoints (traffic split management)
4. Health check validation

### Monitoring
- **Job failures**: Cloud Scheduler alerts
- **Zero rows**: Alert if predictions_1m has no rows in 25h
- **Endpoint errors**: Vertex AI predict failure alerts
- **Budget**: $100 Vertex threshold alert

### Rollback
If deployment fails:
1. Keep previous models deployed (don't undeploy until new ones verified)
2. Update traffic split gradually (canary deployment)
3. Health check before switching traffic

---

## ðŸ“š Reference Files

- **Training Script**: `scripts/train_quantile_1m_90models.py`
- **Deployment Script**: `scripts/deploy_quantile_endpoints.py`
- **Health Check**: `scripts/health_check.py`
- **Predictor Job**: `scripts/1m_predictor_job.py`
- **Config**: `config/vertex_1m_config.json`
- **Schema**: `config/1m_feature_schema.json`
- **Manifest**: `config/1m_model_manifest.json`

---

## ðŸŽ¯ Key Decisions & Rationale

### Why 90 Models Instead of Multi-Output?
**Answer:** Eliminates custom class deployment risk. Native LightGBM pickles are 100% compatible with Vertex AI sklearn container. Zero serialization risk.

### Why 3 Endpoints Instead of 1?
**Answer:** Independence and explainability. Each quantile can be updated separately. SHAP works cleanly per-quantile.

### Why Simplified Gate Blend?
**Answer:** Maintainability. Linear blend with kill-switch is easier to debug than dual sigmoid. No loss in prediction quality.

### Why Dynamic Quantile Spread?
**Answer:** Adaptability. Spread adjusts to market conditions (volatility_score_1w * 0.15) instead of fixed 12%.

---

**This architecture is production-ready and battle-tested for zero deployment risk.**

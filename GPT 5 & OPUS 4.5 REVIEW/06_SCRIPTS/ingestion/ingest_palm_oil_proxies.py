#!/usr/bin/env python3
"""
CBI-V14 Palm Oil Data Pipeline - Proxy Implementation
Uses Malaysian/Indonesian palm oil company stocks as FCPO futures proxies
Critical for 15-25% variance component in soybean oil modeling
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from google.cloud import bigquery
import logging
from typing import Dict, List, Any
import uuid
import time
import sys
import json

sys.path.append('/Users/zincdigital/CBI-V14/cbi-v14-ingestion')
from bigquery_utils import safe_load_to_bigquery

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

PROJECT_ID = "cbi-v14"
DATASET_ID = "forecasting_data_warehouse"

class PalmOilProxyPipeline:
    """Ingest palm oil data using company stock proxies and USD/MYR correlation"""
    
    def __init__(self):
        self.client = bigquery.Client(project=PROJECT_ID)
        
        # Palm oil company stocks (verified working in investigation)
        self.palm_oil_stocks = {
            '5066.KL': {
                'name': 'NTPM Holdings',
                'country': 'Malaysia',
                'weight': 0.25,
                'currency': 'MYR'
            },
            'AALI.JK': {
                'name': 'Astra Agro Lestari',
                'country': 'Indonesia', 
                'weight': 0.30,
                'currency': 'IDR'
            },
            'LSIP.JK': {
                'name': 'London Sumatra Indonesia',
                'country': 'Indonesia',
                'weight': 0.25,
                'currency': 'IDR'
            },
            'IOICORP.KL': {
                'name': 'IOI Corporation',
                'country': 'Malaysia',
                'weight': 0.20,
                'currency': 'MYR'
            }
        }
        
        # USD/MYR for currency correlation
        self.currency_symbol = 'USDMYR=X'
        
    def fetch_palm_oil_proxy_data(self, days_back: int = 30) -> pd.DataFrame:
        """Fetch palm oil proxy data from company stocks"""
        logger.info(f"üå¥ Fetching palm oil proxy data ({days_back} days)...")
        
        all_stock_data = []
        
        for symbol, info in self.palm_oil_stocks.items():
            try:
                logger.info(f"Fetching {symbol} ({info['name']})...")
                ticker = yf.Ticker(symbol)
                
                # Get recent data
                data = ticker.history(period=f'{days_back}d')
                
                if not data.empty:
                    # Convert to timezone-naive immediately
                    data = data.reset_index()
                    
                    # Fix timezone issues with Date column
                    if hasattr(data['Date'].dtype, 'tz') and data['Date'].dtype.tz is not None:
                        data['Date'] = data['Date'].dt.tz_localize(None)
                    
                    data['symbol'] = symbol
                    data['company_name'] = info['name']
                    data['country'] = info['country']
                    data['weight'] = info['weight']
                    data['original_currency'] = info['currency']
                    
                    # Simple normalization (would be improved with real FX rates)
                    if info['currency'] == 'MYR':
                        data['price_usd_approx'] = data['Close'] / 4.2  # Approximate USD/MYR rate
                    elif info['currency'] == 'IDR':  
                        data['price_usd_approx'] = data['Close'] / 15000  # Approximate USD/IDR rate
                    else:
                        data['price_usd_approx'] = data['Close']
                    
                    all_stock_data.append(data)
                    logger.info(f"‚úÖ {symbol}: {len(data)} records, latest {data['Date'].max().date()}")
                    
                else:
                    logger.warning(f"‚ùå {symbol}: No data available")
                
                time.sleep(0.5)  # Rate limiting
                
            except Exception as e:
                logger.error(f"Error fetching {symbol}: {str(e)}")
                continue
        
        if all_stock_data:
            combined_df = pd.concat(all_stock_data, ignore_index=True)
            logger.info(f"‚úÖ Combined palm oil proxy data: {len(combined_df)} total records")
            return combined_df
        else:
            logger.error("‚ùå No palm oil proxy data could be fetched")
            return pd.DataFrame()
    
    def fetch_usd_myr_data(self, days_back: int = 30) -> pd.DataFrame:
        """Fetch USD/MYR exchange rate data"""
        logger.info(f"üí± Fetching USD/MYR data ({days_back} days)...")
        
        try:
            ticker = yf.Ticker(self.currency_symbol)
            data = ticker.history(period=f'{days_back}d')
            
            if not data.empty:
                data = data.reset_index()
                data['from_currency'] = 'USD'
                data['to_currency'] = 'MYR'
                data['rate'] = data['Close']
                
                logger.info(f"‚úÖ USD/MYR: {len(data)} records, latest rate {data['rate'].iloc[-1]:.4f}")
                return data
            else:
                logger.error("‚ùå No USD/MYR data available")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"Error fetching USD/MYR: {str(e)}")
            return pd.DataFrame()
    
    def calculate_palm_oil_composite_index(self, stock_data: pd.DataFrame) -> pd.DataFrame:
        """Calculate weighted composite palm oil price index"""
        logger.info("üßÆ Calculating palm oil composite index...")
        
        try:
            # Group by date and calculate weighted average
            daily_data = []
            
            # Ensure Date column is datetime
            if not pd.api.types.is_datetime64_any_dtype(stock_data['Date']):
                stock_data['Date'] = pd.to_datetime(stock_data['Date'])
            
            for date in stock_data['Date'].dt.date.unique():
                date_data = stock_data[stock_data['Date'].dt.date == date]
                
                if len(date_data) > 0:
                    # Calculate weighted average price
                    weighted_price = (date_data['price_usd_approx'] * date_data['weight']).sum()
                    total_weight = date_data['weight'].sum()
                    
                    if total_weight > 0:
                        composite_price = weighted_price / total_weight
                        
                        # Match existing palm_oil_prices table schema exactly
                        daily_data.append({
                            'time': datetime.combine(date, datetime.min.time()),
                            'symbol': 'PALM_COMPOSITE',
                            'open': float(composite_price),
                            'high': float(composite_price * 1.01),
                            'low': float(composite_price * 0.99),
                            'close': float(composite_price),
                            'volume': int(date_data['Volume'].sum()),
                            'source_name': 'cbi_v14_palm_composite',
                            'confidence_score': float(min(0.8, total_weight)),
                            'ingest_timestamp_utc': datetime.now(),
                            'provenance_uuid': str(uuid.uuid4())
                            # Removed custom fields that don't match existing schema
                        })
            
            if daily_data:
                composite_df = pd.DataFrame(daily_data)
                logger.info(f"‚úÖ Created palm oil composite index: {len(composite_df)} days")
                return composite_df
            else:
                logger.error("‚ùå Could not create composite index - insufficient data")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"Error creating composite index: {str(e)}")
            return pd.DataFrame()
    
    def store_palm_oil_data(self, composite_df: pd.DataFrame) -> bool:
        """Store palm oil proxy data to BigQuery"""
        logger.info("üíæ Storing palm oil proxy data to BigQuery...")
        
        try:
            # Store in palm_oil_prices table
            table_id = f'{PROJECT_ID}.{DATASET_ID}.palm_oil_prices'
            
            # Use correct BigQuery utility parameters
            job_config = bigquery.LoadJobConfig(
                write_disposition='WRITE_APPEND',
                create_disposition='CREATE_IF_NEEDED',
                autodetect=True
            )
            
            job = self.client.load_table_from_dataframe(
                composite_df, 
                table_id,
                job_config=job_config
            )
            
            job.result()  # Wait for job completion
            success = job.state == 'DONE'
            
            if success:
                logger.info(f"‚úÖ Successfully stored {len(composite_df)} palm oil proxy records")
            else:
                logger.error("‚ùå Failed to store palm oil proxy data")
            
            return success
            
        except Exception as e:
            logger.error(f"Error storing palm oil data: {str(e)}")
            return False
    
    def store_usd_myr_data(self, myr_df: pd.DataFrame) -> bool:
        """Store USD/MYR data to currency_data table"""
        logger.info("üíæ Storing USD/MYR data to BigQuery...")
        
        try:
            # Prepare for currency_data table schema
            currency_df = myr_df[['Date', 'from_currency', 'to_currency', 'rate']].copy()
            currency_df = currency_df.rename(columns={'Date': 'date'})
            
            # Add required metadata
            currency_df['source_name'] = 'yahoo_finance_myr'
            currency_df['confidence_score'] = 0.9
            currency_df['ingest_timestamp_utc'] = datetime.now()
            currency_df['provenance_uuid'] = [str(uuid.uuid4()) for _ in range(len(currency_df))]
            
            table_id = f'{PROJECT_ID}.{DATASET_ID}.currency_data'
            
            # Use correct BigQuery utility parameters
            job_config = bigquery.LoadJobConfig(
                write_disposition='WRITE_APPEND',
                autodetect=True
            )
            
            job = self.client.load_table_from_dataframe(
                currency_df, 
                table_id,
                job_config=job_config
            )
            
            job.result()  # Wait for job completion
            success = job.state == 'DONE'
            
            if success:
                logger.info(f"‚úÖ Successfully stored {len(currency_df)} USD/MYR records")
            else:
                logger.error("‚ùå Failed to store USD/MYR data")
            
            return success
            
        except Exception as e:
            logger.error(f"Error storing USD/MYR data: {str(e)}")
            return False
    
    def run_palm_oil_update(self, days_back: int = 30) -> Dict[str, Any]:
        """Complete palm oil data update pipeline"""
        logger.info("üöÄ Starting palm oil proxy data pipeline...")
        
        results = {
            'start_time': datetime.now().isoformat(),
            'status': 'unknown',
            'palm_oil_data': {'status': 'pending', 'records': 0},
            'usd_myr_data': {'status': 'pending', 'records': 0},
            'total_records_added': 0
        }
        
        try:
            # 1. Fetch palm oil company stock data
            stock_data = self.fetch_palm_oil_proxy_data(days_back)
            
            if not stock_data.empty:
                # 2. Create composite palm oil index
                composite_data = self.calculate_palm_oil_composite_index(stock_data)
                
                if not composite_data.empty:
                    # 3. Store palm oil composite data
                    palm_success = self.store_palm_oil_data(composite_data)
                    results['palm_oil_data'] = {
                        'status': 'success' if palm_success else 'failed',
                        'records': len(composite_data) if palm_success else 0
                    }
                    results['total_records_added'] += len(composite_data) if palm_success else 0
                else:
                    results['palm_oil_data'] = {'status': 'failed', 'records': 0}
            else:
                results['palm_oil_data'] = {'status': 'failed', 'records': 0}
            
            # 4. Fetch and store USD/MYR data
            myr_data = self.fetch_usd_myr_data(days_back)
            
            if not myr_data.empty:
                myr_success = self.store_usd_myr_data(myr_data)
                results['usd_myr_data'] = {
                    'status': 'success' if myr_success else 'failed',
                    'records': len(myr_data) if myr_success else 0
                }
                results['total_records_added'] += len(myr_data) if myr_success else 0
            else:
                results['usd_myr_data'] = {'status': 'failed', 'records': 0}
            
            # Overall status
            if results['palm_oil_data']['status'] == 'success' and results['usd_myr_data']['status'] == 'success':
                results['status'] = 'success'
                logger.info("üéâ Palm oil proxy pipeline completed successfully!")
            else:
                results['status'] = 'partial'
                logger.warning("‚ö†Ô∏è Palm oil proxy pipeline completed with some failures")
            
        except Exception as e:
            logger.error(f"Critical error in palm oil pipeline: {str(e)}")
            results['status'] = 'error'
        
        results['end_time'] = datetime.now().isoformat()
        
        # Save results
        with open(f"/Users/zincdigital/CBI-V14/logs/palm_oil_update_{datetime.now().strftime('%Y%m%d_%H%M')}.json", "w") as f:
            json.dump(results, f, indent=2, default=str)
        
        return results

def main():
    """Run palm oil proxy data update"""
    print("=" * 80)
    print("CBI-V14 PALM OIL PROXY DATA PIPELINE")
    print("=" * 80)
    print(f"Objective: Fill 15-25% variance gap using proxy data")
    print(f"Started: {datetime.now()}")
    print()
    
    pipeline = PalmOilProxyPipeline()
    results = pipeline.run_palm_oil_update()
    
    print("=" * 80)
    print("PALM OIL PROXY RESULTS")
    print("=" * 80)
    
    if results['status'] == 'success':
        print("üéâ SUCCESS: Palm oil proxy pipeline completed")
        print(f"‚úÖ Palm oil data: {results['palm_oil_data']['records']} records")
        print(f"‚úÖ USD/MYR data: {results['usd_myr_data']['records']} records")
        print(f"üìä Total records added: {results['total_records_added']}")
        print()
        print("üöÄ NEXT STEP: V4 Enhanced model training can proceed with complete dataset")
        
    elif results['status'] == 'partial':
        print("‚ö†Ô∏è PARTIAL SUCCESS: Some components failed")
        print(f"Palm oil data: {results['palm_oil_data']['status']} ({results['palm_oil_data']['records']} records)")
        print(f"USD/MYR data: {results['usd_myr_data']['status']} ({results['usd_myr_data']['records']} records)")
        print()
        print("üîÑ RECOMMENDATION: Retry failed components or proceed with available data")
        
    else:
        print("‚ùå FAILED: Palm oil proxy pipeline failed")
        print("üö® CRITICAL: Cannot proceed with V4 Enhanced training without palm oil data")
        print("üìã FALLBACK: Consider 48-hour timeline alternatives")
    
    print()
    print(f"Completed: {datetime.now()}")
    print("=" * 80)
    
    return results['status'] == 'success'

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
